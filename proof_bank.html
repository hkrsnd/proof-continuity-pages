<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>RAILS &mdash; Proof Bank</title>
<style>
* { margin: 0; padding: 0; box-sizing: border-box; }
body {
    font-family: 'Segoe UI', system-ui, -apple-system, sans-serif;
    background: #f8f9fa;
    color: #1a1a2e;
    line-height: 1.6;
    padding: 2rem;
    max-width: 1100px;
    margin: 0 auto;
}
a { color: #2563eb; text-decoration: none; }
a:hover { text-decoration: underline; }

/* Header */
.breadcrumb { font-size: 0.82rem; color: #94a3b8; margin-bottom: 1rem; }
.breadcrumb a { color: #64748b; }
h1 { font-size: 1.8rem; margin-bottom: 0.3rem; color: #16213e; }
.subtitle { color: #666; font-size: 0.95rem; margin-bottom: 2rem; }

/* Progress overview bar */
.progress-overview {
    background: white; border-radius: 12px; padding: 1.5rem;
    margin-bottom: 2rem; box-shadow: 0 1px 3px rgba(0,0,0,0.08);
}
.progress-overview h2 { font-size: 1.1rem; color: #16213e; margin-bottom: 1rem; }
.progress-bar-container {
    background: #e5e7eb; border-radius: 8px; height: 28px; overflow: hidden;
    display: flex; margin-bottom: 0.8rem;
}
.progress-segment {
    height: 100%; display: flex; align-items: center; justify-content: center;
    font-size: 0.7rem; font-weight: 700; color: white; transition: width 0.5s;
    min-width: 0; overflow: hidden; white-space: nowrap;
}
.seg-done { background: #16a34a; }
.seg-active { background: #2563eb; background-image: repeating-linear-gradient(-45deg, transparent, transparent 6px, rgba(255,255,255,0.15) 6px, rgba(255,255,255,0.15) 12px); animation: barberpole 1s linear infinite; }
@keyframes barberpole { 0% { background-position: 0 0; } 100% { background-position: 24px 0; } }
.seg-todo { background: #e5e7eb; }
.progress-legend {
    display: flex; gap: 1.5rem; font-size: 0.78rem; color: #555; flex-wrap: wrap;
}
.legend-item { display: flex; align-items: center; gap: 0.35rem; }
.legend-dot { width: 10px; height: 10px; border-radius: 3px; flex-shrink: 0; }
.legend-dot.done { background: #16a34a; }
.legend-dot.active { background: #2563eb; }
.legend-dot.todo { background: #d1d5db; }

/* Stats */
.stats-grid {
    display: grid; grid-template-columns: repeat(auto-fit, minmax(130px, 1fr));
    gap: 0.8rem; margin: 1rem 0;
}
.stat-card {
    background: #f0f4ff; border-radius: 8px; padding: 0.7rem 0.8rem; text-align: center;
}
.stat-val { font-size: 1.4rem; font-weight: 700; color: #2563eb; }
.stat-lbl { font-size: 0.72rem; color: #666; margin-top: 0.15rem; }
.stat-card.green .stat-val { color: #16a34a; }
.stat-card.amber .stat-val { color: #d97706; }

/* Section */
.section { margin-bottom: 2rem; }
.section-header {
    display: flex; align-items: center; gap: 0.8rem; margin-bottom: 1rem;
}
.section-num {
    display: inline-flex; align-items: center; justify-content: center;
    width: 32px; height: 32px; border-radius: 8px;
    font-size: 0.85rem; font-weight: 700; color: white; flex-shrink: 0;
}
.sn-blue { background: #2563eb; }
.sn-purple { background: #7c3aed; }
.sn-amber { background: #d97706; }
.sn-green { background: #16a34a; }
.sn-rose { background: #e11d48; }
.sn-teal { background: #0d9488; }
.sn-slate { background: #475569; }
.sn-indigo { background: #4f46e5; }
.section-title-text { font-size: 1.25rem; font-weight: 700; color: #16213e; }

/* Card */
.card {
    background: white; border-radius: 12px; padding: 1.5rem;
    margin-bottom: 1rem; box-shadow: 0 1px 3px rgba(0,0,0,0.08);
}
.card p { font-size: 0.88rem; color: #555; margin-bottom: 0.6rem; }

/* Composition table */
.table-wrap { overflow-x: auto; margin: 0.8rem 0; }
table { width: 100%; border-collapse: collapse; font-size: 0.82rem; }
th {
    background: #f0f4ff; color: #1e40af; font-weight: 600;
    text-transform: uppercase; letter-spacing: 0.04em; font-size: 0.72rem;
    padding: 0.6rem 0.6rem; text-align: center;
    border-bottom: 2px solid #dbeafe; white-space: nowrap;
}
th:first-child { text-align: left; }
td {
    padding: 0.5rem 0.6rem; text-align: center;
    border-bottom: 1px solid #f0f0f0;
}
td:first-child { text-align: left; font-weight: 500; }
tr:hover { background: #fafbff; }
.row-total td { font-weight: 700; border-top: 2px solid #e2e8f0; background: #f8fafc; }
.domain-math { border-left: 3px solid #2563eb; }
.domain-logic { border-left: 3px solid #7c3aed; }
.domain-code { border-left: 3px solid #d97706; }
.domain-science { border-left: 3px solid #0d9488; }

/* Donut chart */
.donut-container { display: flex; align-items: center; justify-content: center; gap: 2rem; flex-wrap: wrap; margin: 1rem 0; }
.donut-chart { position: relative; width: 160px; height: 160px; }
.donut-chart svg { transform: rotate(-90deg); }
.donut-center {
    position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%);
    text-align: center;
}
.donut-center .big { font-size: 1.4rem; font-weight: 700; color: #16213e; }
.donut-center .small { font-size: 0.7rem; color: #666; }
.donut-legend { display: flex; flex-direction: column; gap: 0.5rem; }
.donut-legend-item { display: flex; align-items: center; gap: 0.5rem; font-size: 0.82rem; }
.donut-legend-color { width: 14px; height: 14px; border-radius: 4px; flex-shrink: 0; }

/* Task checklist */
.task-list { list-style: none; padding: 0; }
.task-item {
    display: flex; align-items: flex-start; gap: 0.6rem;
    padding: 0.6rem 0.8rem; border-radius: 8px; margin-bottom: 0.4rem;
    font-size: 0.85rem; transition: background 0.15s;
}
.task-item:hover { background: #f8fafc; }
.task-check {
    width: 20px; height: 20px; border-radius: 5px; flex-shrink: 0;
    display: flex; align-items: center; justify-content: center;
    font-size: 0.75rem; font-weight: 700; margin-top: 1px;
}
.check-done { background: #dcfce7; color: #16a34a; border: 2px solid #86efac; }
.check-active { background: #dbeafe; color: #2563eb; border: 2px solid #93c5fd; }
.check-todo { background: #f3f4f6; color: #9ca3af; border: 2px solid #d1d5db; }
.task-content { flex: 1; }
.task-title { font-weight: 600; color: #1a1a2e; }
.task-done .task-title { color: #16a34a; text-decoration: line-through; text-decoration-color: #86efac; }
.task-desc { font-size: 0.78rem; color: #888; margin-top: 0.15rem; }
.task-badges { display: flex; gap: 0.4rem; margin-top: 0.3rem; flex-wrap: wrap; }
.badge {
    display: inline-block; padding: 0.1rem 0.45rem; border-radius: 12px;
    font-size: 0.68rem; font-weight: 600;
}
.b-blue { background: #dbeafe; color: #1e40af; }
.b-green { background: #dcfce7; color: #166534; }
.b-amber { background: #fef3c7; color: #92400e; }
.b-purple { background: #f3e8ff; color: #6b21a8; }
.b-rose { background: #ffe4e6; color: #9f1239; }
.b-gray { background: #f3f4f6; color: #4b5563; }

/* Sub-task breakdown within a card */
.sub-task {
    display: flex; align-items: center; gap: 0.5rem; padding: 0.35rem 0;
    font-size: 0.82rem; color: #555;
}
.sub-check {
    width: 16px; height: 16px; border-radius: 4px; flex-shrink: 0;
    display: flex; align-items: center; justify-content: center;
    font-size: 0.65rem; font-weight: 700;
}

/* Domain cards grid */
.domain-grid {
    display: grid; grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
    gap: 1rem; margin: 1rem 0;
}
.domain-card {
    background: white; border-radius: 12px; padding: 1.2rem;
    box-shadow: 0 1px 3px rgba(0,0,0,0.08); border-top: 3px solid;
}
.domain-card h3 { font-size: 1rem; margin-bottom: 0.3rem; }
.domain-card .target { font-size: 0.82rem; color: #666; margin-bottom: 0.6rem; }
.domain-card .current { font-size: 0.82rem; font-weight: 600; margin-bottom: 0.5rem; }
.domain-progress {
    background: #e5e7eb; border-radius: 6px; height: 8px; overflow: hidden;
    margin-bottom: 0.5rem;
}
.domain-progress-fill { height: 100%; border-radius: 6px; transition: width 0.5s; }
.domain-sources { font-size: 0.75rem; color: #888; }

/* Code blocks */
.code-block {
    background: #1e293b; color: #e2e8f0; border-radius: 8px;
    padding: 1rem; font-family: 'Fira Code', 'SF Mono', 'Menlo', monospace;
    font-size: 0.78rem; overflow-x: auto; margin: 0.8rem 0; line-height: 1.5;
}
.code-block .tag { color: #7dd3fc; }
.code-block .attr { color: #fbbf24; }
.code-block .str { color: #86efac; }
.code-block .comment { color: #64748b; }

/* Critical path */
.critical-path {
    display: flex; align-items: center; gap: 0; flex-wrap: wrap;
    margin: 1rem 0;
}
.cp-node {
    padding: 0.5rem 0.9rem; border-radius: 8px; font-size: 0.78rem;
    font-weight: 600; white-space: nowrap;
}
.cp-done { background: #dcfce7; color: #166534; }
.cp-active { background: #dbeafe; color: #1e40af; border: 2px dashed #93c5fd; }
.cp-todo { background: #f3f4f6; color: #6b7280; }
.cp-arrow { font-size: 1.1rem; color: #94a3b8; padding: 0 0.2rem; font-weight: 700; }

/* Verification cards */
.verify-grid {
    display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
    gap: 0.8rem; margin: 0.8rem 0;
}
.verify-card {
    padding: 0.8rem; background: #f9fafb; border-radius: 8px;
    border-left: 3px solid; font-size: 0.82rem;
}
.verify-card h4 { font-size: 0.85rem; color: #16213e; margin-bottom: 0.2rem; }
.verify-card p { font-size: 0.78rem; color: #666; }

/* Explorer */
.explorer-controls {
    display: grid; grid-template-columns: repeat(auto-fit, minmax(180px, 1fr));
    gap: 0.7rem; margin: 0.8rem 0 0.6rem;
}
.control label {
    display: block; font-size: 0.72rem; color: #64748b; margin-bottom: 0.25rem;
    text-transform: uppercase; letter-spacing: 0.04em; font-weight: 600;
}
.control input, .control select {
    width: 100%; border: 1px solid #d1d5db; border-radius: 8px; padding: 0.45rem 0.55rem;
    font-size: 0.82rem; background: white; color: #1a1a2e;
}
.explorer-meta { font-size: 0.8rem; color: #64748b; margin-bottom: 0.7rem; }
.explorer-layout {
    display: grid; grid-template-columns: 320px 1fr; gap: 0.8rem;
}
.example-list {
    border: 1px solid #e5e7eb; border-radius: 10px; background: #fbfdff;
    max-height: 680px; overflow-y: auto;
}
.example-row {
    padding: 0.6rem 0.7rem; border-bottom: 1px solid #eef2f7; cursor: pointer;
}
.example-row:hover { background: #f1f5ff; }
.example-row.active { background: #e9f0ff; border-left: 3px solid #2563eb; }
.example-row:last-child { border-bottom: 0; }
.row-id { font-size: 0.77rem; font-family: monospace; color: #334155; margin-bottom: 0.15rem; }
.row-meta { font-size: 0.74rem; color: #64748b; display: flex; gap: 0.35rem; flex-wrap: wrap; }
.row-chip {
    display: inline-block; padding: 0.1rem 0.35rem; border-radius: 10px; font-size: 0.68rem;
    font-weight: 600;
}
.chip-dataset { background: #e0e7ff; color: #3730a3; }
.chip-steps { background: #dcfce7; color: #166534; }
.chip-verify { background: #fef3c7; color: #92400e; }
.example-detail {
    border: 1px solid #e5e7eb; border-radius: 10px; background: #ffffff;
    padding: 0.9rem; max-height: 680px; overflow-y: auto;
}
.detail-title { font-size: 0.92rem; font-weight: 700; color: #1e293b; margin-bottom: 0.25rem; }
.detail-meta { font-size: 0.76rem; color: #64748b; margin-bottom: 0.65rem; }
.detail-prompt {
    background: #f8fafc; border-left: 3px solid #94a3b8; padding: 0.6rem 0.7rem;
    border-radius: 0 6px 6px 0; font-size: 0.8rem; color: #374151; margin-bottom: 0.7rem;
    white-space: pre-wrap;
}
.proof-step {
    border-radius: 8px; padding: 0.55rem 0.7rem; margin-bottom: 0.45rem;
}
.proof-step.premise { background: #eff6ff; border-left: 4px solid #3b82f6; }
.proof-step.derived { background: #f0fdf4; border-left: 4px solid #22c55e; }
.proof-head { font-size: 0.77rem; color: #374151; font-weight: 700; margin-bottom: 0.2rem; }
.proof-text { font-size: 0.8rem; color: #475569; margin-bottom: 0.25rem; }
.proof-logic {
    background: rgba(0, 0, 0, 0.05); border-radius: 5px; padding: 0.35rem 0.45rem;
    font-family: "SF Mono", Menlo, Consolas, monospace; font-size: 0.76rem; color: #6d28d9;
    white-space: pre-wrap; overflow-wrap: anywhere;
}
.no-results {
    padding: 0.75rem; color: #64748b; font-size: 0.82rem;
}

/* Timeline */
.timeline { position: relative; padding-left: 2rem; margin: 1rem 0; }
.timeline::before {
    content: ''; position: absolute; left: 0.5rem; top: 0; bottom: 0;
    width: 2px; background: #e5e7eb;
}
.tl-item { position: relative; margin-bottom: 1.2rem; }
.tl-dot {
    position: absolute; left: -1.65rem; top: 0.15rem;
    width: 12px; height: 12px; border-radius: 50%;
}
.tl-dot.done { background: #16a34a; }
.tl-dot.active { background: #2563eb; box-shadow: 0 0 0 3px rgba(37, 99, 235, 0.2); }
.tl-dot.todo { background: #d1d5db; }
.tl-title { font-size: 0.88rem; font-weight: 600; color: #16213e; }
.tl-desc { font-size: 0.78rem; color: #888; }
.tl-files { font-size: 0.72rem; color: #a0aec0; font-family: monospace; margin-top: 0.2rem; }

/* Footer */
.footer {
    text-align: center; color: #94a3b8; font-size: 0.78rem;
    margin-top: 3rem; padding-top: 1rem; border-top: 1px solid #e5e7eb;
}

/* Responsive */
@media (max-width: 600px) {
    body { padding: 1rem; }
    .stats-grid { grid-template-columns: repeat(2, 1fr); }
    .donut-container { flex-direction: column; }
}
@media (max-width: 920px) {
    .explorer-layout { grid-template-columns: 1fr; }
    .example-list, .example-detail { max-height: 460px; }
}
</style>
</head>
<body>

<p class="breadcrumb"><a href="index.html">RAILS Hub</a> / Proof Bank</p>
<h1>Proof Bank</h1>
<p class="subtitle">Verified SFT reasoning traces in <code>&lt;think&gt;</code> + <code>&lt;step&gt;</code> format &middot; currently tracking the first 5% pilot batch across logic, math, and coding datasets</p>

<!-- ===== PROGRESS OVERVIEW ===== -->
<div class="progress-overview">
    <h2>Pilot Progress</h2>
    <div class="stats-grid">
        <div class="stat-card green"><div class="stat-val" id="pb-stat-total">-</div><div class="stat-lbl">Verified Traces (Pilot)</div></div>
        <div class="stat-card"><div class="stat-val">5,000</div><div class="stat-lbl">Pilot Milestone (5%)</div></div>
        <div class="stat-card green"><div class="stat-val" id="pb-stat-progress">-</div><div class="stat-lbl">Milestone Coverage</div></div>
        <div class="stat-card"><div class="stat-val" id="pb-stat-datasets">-</div><div class="stat-lbl">Base Datasets</div></div>
        <div class="stat-card"><div class="stat-val" id="pb-stat-domains">-</div><div class="stat-lbl">Active Domains</div></div>
        <div class="stat-card"><div class="stat-val" id="pb-stat-avg-steps">-</div><div class="stat-lbl">Avg Steps / Trace</div></div>
    </div>
    <div class="progress-bar-container">
        <div class="progress-segment seg-done" id="pb-seg-logic" style="width: 34%; background: #7c3aed;" title="Logic datasets in pilot">Logic</div>
        <div class="progress-segment seg-done" id="pb-seg-math" style="width: 33%; background: #2563eb;" title="Math datasets in pilot">Math</div>
        <div class="progress-segment seg-done" id="pb-seg-code" style="width: 33%; background: #d97706;" title="Code datasets in pilot">Code</div>
    </div>
    <div class="progress-legend">
        <span class="legend-item"><span class="legend-dot done"></span> <span id="pb-legend-logic">Logic: -</span></span>
        <span class="legend-item"><span class="legend-dot active"></span> <span id="pb-legend-math">Math: -</span></span>
        <span class="legend-item"><span class="legend-dot done" style="background:#d97706;"></span> <span id="pb-legend-code">Code: -</span></span>
        <span class="legend-item"><span class="legend-dot todo"></span> Explorer payload: <span id="pb-generated-at">-</span></span>
    </div>
</div>

<!-- ===== CONTEXT ===== -->
<div class="section" id="why-proof-bank">
    <div class="section-header">
        <div class="section-num sn-slate">S</div>
        <div class="section-title-text">Current Setup</div>
    </div>
    <div class="card">
        <p>The active Proof Bank setup is a <strong>verified pilot batch</strong> for multi-dataset SFT. It includes the core logic benchmarks (<strong>LogicBench, FOLIO, ProofWriter</strong>) and extends to newly introduced <strong>math</strong> and <strong>coding</strong> datasets.</p>
        <ul style="font-size: 0.85rem; color: #555; padding-left: 1.2rem; margin: 0.5rem 0;">
            <li>Goal for this phase: validate quality before scaling to the full dataset.</li>
            <li>Every shown example includes parsed <code>&lt;step&gt;</code> proof trees and verification metadata.</li>
            <li>The explorer below is the primary interface for inspecting individual traces by base dataset.</li>
        </ul>
        <div class="stats-grid" style="margin-top: 0.8rem;">
            <div class="stat-card"><div class="stat-val" id="pb-ctx-datasets" style="font-size: 1.1rem;">-</div><div class="stat-lbl">Base Datasets</div></div>
            <div class="stat-card"><div class="stat-val" id="pb-ctx-min-steps" style="font-size: 1.1rem;">-</div><div class="stat-lbl">Min Steps</div></div>
            <div class="stat-card"><div class="stat-val" id="pb-ctx-max-steps" style="font-size: 1.1rem;">-</div><div class="stat-lbl">Max Steps</div></div>
            <div class="stat-card green"><div class="stat-val" id="pb-ctx-parse" style="font-size: 1.1rem;">-</div><div class="stat-lbl">Parse Success</div></div>
        </div>
        <p style="margin-top: 0.8rem;"><strong>Pipeline</strong>: convert source reasoning data into <code>&lt;think&gt;</code> + <code>&lt;step&gt;</code> format, run answer/structure checks, and keep only verified outputs for SFT.</p>
    </div>
</div>

<!-- ===== INTERACTIVE EXPLORER ===== -->
<div class="section" id="trace-explorer">
    <div class="section-header">
        <div class="section-num sn-indigo">E</div>
        <div class="section-title-text">Generated Trace Explorer</div>
    </div>
    <div class="card">
        <p>Inspect verified traces from different base datasets and review each proof tree step-by-step.</p>

        <div class="explorer-controls">
            <div class="control">
                <label for="dataset-filter">Dataset</label>
                <select id="dataset-filter">
                    <option value="all">All datasets</option>
                </select>
            </div>
            <div class="control">
                <label for="search-filter">Search</label>
                <input id="search-filter" type="text" placeholder="id, theory, logic text..." />
            </div>
            <div class="control">
                <label for="min-steps">Min Steps</label>
                <input id="min-steps" type="number" min="0" value="0" />
            </div>
            <div class="control">
                <label for="limit-records">Max Results</label>
                <input id="limit-records" type="number" min="1" max="500" value="120" />
            </div>
        </div>

        <div class="explorer-meta" id="explorer-meta">Loading explorer data...</div>

        <div class="explorer-layout">
            <div class="example-list" id="example-list"></div>
            <div class="example-detail" id="example-detail">
                <div class="no-results">Select an example to inspect its proof tree.</div>
            </div>
        </div>
    </div>
</div>

<!-- ===== TARGET COMPOSITION ===== -->
<div class="section">
    <div class="section-header">
        <div class="section-num sn-blue">C</div>
        <div class="section-title-text">Pilot Dataset Composition</div>
    </div>
    <div class="card">
        <p>Counts below are built directly from <code>proof_tree_explorer_data.json</code> and reflect the currently generated pilot set.</p>

        <div class="table-wrap">
        <table>
            <thead>
                <tr><th>Dataset</th><th>Domain</th><th>Verified</th><th>Share</th><th>Source File</th><th>Status</th></tr>
            </thead>
            <tbody id="pb-dataset-table">
                <tr><td colspan="6">Loading dataset composition...</td></tr>
            </tbody>
        </table>
        </div>
        <p style="font-size:0.82rem; color:#666; margin-top:0.5rem;">The full 100K multi-domain plan is archived below as historical context; the active run is this verified pilot composition.</p>
    </div>
</div>

<!-- ===== DOMAIN PROGRESS CARDS ===== -->
<div class="section">
    <div class="section-header">
        <div class="section-num sn-green">P</div>
        <div class="section-title-text">Pilot Domain Split</div>
    </div>
    <div class="domain-grid">
        <div class="domain-card" style="border-top-color: #7c3aed;">
            <h3 style="color: #7c3aed;">Logic</h3>
            <div class="target">Core benchmark domain</div>
            <div class="current" style="color: #7c3aed;" id="pb-domain-logic-current">Current: -</div>
            <div class="domain-progress"><div class="domain-progress-fill" id="pb-domain-logic-fill" style="width: 0%; background: #7c3aed;"></div></div>
            <div class="domain-sources" id="pb-domain-logic-sources">Loading logic dataset breakdown...</div>
        </div>
        <div class="domain-card" style="border-top-color: #2563eb;">
            <h3 style="color: #2563eb;">Math</h3>
            <div class="target">Active pilot domain</div>
            <div class="current" style="color: #2563eb;" id="pb-domain-math-current">Current: -</div>
            <div class="domain-progress"><div class="domain-progress-fill" id="pb-domain-math-fill" style="width: 0%; background: #2563eb;"></div></div>
            <div class="domain-sources" id="pb-domain-math-sources">Loading math dataset breakdown...</div>
        </div>
        <div class="domain-card" style="border-top-color: #d97706;">
            <h3 style="color: #d97706;">Code</h3>
            <div class="target">Active pilot domain</div>
            <div class="current" style="color: #d97706;" id="pb-domain-code-current">Current: -</div>
            <div class="domain-progress"><div class="domain-progress-fill" id="pb-domain-code-fill" style="width: 0%; background: #d97706;"></div></div>
            <div class="domain-sources" id="pb-domain-code-sources">Loading code dataset breakdown...</div>
        </div>
    </div>
    <div class="card" style="margin-top: 0.5rem;">
        <p style="margin-bottom: 0;"><strong>Legacy note:</strong> detailed 100K roadmap sections below are preserved for reference, but the active setup is the pilot batch summarized above and in the trace explorer.</p>
    </div>
</div>

<!-- ===== STEP 1: INFRASTRUCTURE ===== -->
<div class="section">
    <div class="section-header">
        <div class="section-num sn-blue">1</div>
        <div class="section-title-text">Legacy 100K Roadmap &mdash; Prompt System &amp; Reward Updates</div>
    </div>
    <div class="card">
        <h3 style="font-size: 0.95rem; color: #16213e; margin-bottom: 0.8rem;">1.1 Multi-Answer Prompt System</h3>
        <p><strong>Problem</strong>: <code>prompt/think_cot_prompt.txt</code> hardcodes "The answer is always Yes or No."</p>
        <p><strong>Solution</strong>: Modular prompt system where answer instructions are injected per task type.</p>
        <ul class="task-list">
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">3-class answer support in generate_sft_data.py</div>
                    <div class="task-desc">FOLIO (True/False/Uncertain) and ProofWriter (True/False/Unknown) answer instructions</div>
                </div>
            </li>
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">Create prompt/answer_instructions.py</div>
                    <div class="task-desc">9 answer types: binary, ternary, ternary_unknown, numeric, expression, multichoice, relational, proof, code</div>
                </div>
            </li>
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">Decouple answer instructions from think_cot_prompt.txt</div>
                    <div class="task-desc">Removed hardcoded lines 30&ndash;32; dynamic injection via get_answer_instruction()</div>
                </div>
            </li>
        </ul>

        <h3 style="font-size: 0.95rem; color: #16213e; margin: 1.2rem 0 0.8rem;">1.2 Domain-Specific &lt;logic&gt; Guidelines</h3>
        <ul class="task-list">
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">Logic supplement (existing behavior)</div>
                    <div class="task-desc">Prolog-style predicates, :- implications, ~ negation</div>
                </div>
            </li>
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">Create prompt/math_supplement.txt</div>
                    <div class="task-desc">Algebraic expressions, equation transformations, standard math notation</div>
                </div>
            </li>
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">Create prompt/code_supplement.txt</div>
                    <div class="task-desc">Executable Python snippets, self-contained operations per step</div>
                </div>
            </li>
        </ul>

        <h3 style="font-size: 0.95rem; color: #16213e; margin: 1.2rem 0 0.8rem;">1.3 Reward Function Updates</h3>
        <ul class="task-list">
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">_canonicalize_answer() with cross-format matching</div>
                    <div class="task-desc">yes/true, no/false, uncertain/unknown equivalence in reward.py</div>
                </div>
            </li>
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">reward_proof_quality() for partial credit</div>
                    <div class="task-desc">Score proof chain quality independent of final answer</div>
                </div>
            </li>
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">Extend answer matching for numeric, multichoice, expression types</div>
                    <div class="task-desc">5 matching strategies: direct, canonical, numeric (1e-6 tol), multichoice, SymPy expression</div>
                </div>
            </li>
        </ul>
    </div>
</div>

<!-- ===== STEP 2: DATASET DOWNLOADS ===== -->
<div class="section">
    <div class="section-header">
        <div class="section-num sn-purple">2</div>
        <div class="section-title-text">Dataset Downloads</div>
    </div>
    <div class="card">
        <p>Unified HuggingFace downloader &mdash; <code>experiments/download_datasets.py</code></p>
        <div class="table-wrap">
        <table>
            <thead>
                <tr><th>Dataset</th><th>HuggingFace ID</th><th>Est. Size</th><th>Domain</th><th>Status</th></tr>
            </thead>
            <tbody>
                <tr>
                    <td>OpenR1-Math-220k</td><td style="font-size:0.75rem; font-family: monospace;">open-r1/OpenR1-Math-220k</td><td>220K</td><td><span class="badge b-blue">Math</span></td>
                    <td><span class="badge b-green">50K converted</span></td>
                </tr>
                <tr>
                    <td>GSM8K</td><td style="font-size:0.75rem; font-family: monospace;">openai/gsm8k</td><td>7.5K</td><td><span class="badge b-blue">Math</span></td>
                    <td><span class="badge b-green">6.5K converted</span></td>
                </tr>
                <tr>
                    <td>MATH</td><td style="font-size:0.75rem; font-family: monospace;">hendrycks/competition_math</td><td>12.5K</td><td><span class="badge b-blue">Math</span></td>
                    <td><span class="badge b-gray">Not started</span></td>
                </tr>
                <tr>
                    <td>EntailmentBank</td><td style="font-size:0.75rem; font-family: monospace;">allenai/entailmentbank</td><td>~1.8K</td><td><span class="badge b-purple">Logic</span></td>
                    <td><span class="badge b-gray">Not started</span></td>
                </tr>
                <tr>
                    <td>RuleTaker</td><td style="font-size:0.75rem; font-family: monospace;">Allen AI</td><td>~560K</td><td><span class="badge b-purple">Logic</span></td>
                    <td><span class="badge b-gray">Not started</span></td>
                </tr>
                <tr>
                    <td>CLUTRR</td><td style="font-size:0.75rem; font-family: monospace;">CLUTRR/v1.0</td><td>~10K</td><td><span class="badge b-purple">Logic</span></td>
                    <td><span class="badge b-gray">Not started</span></td>
                </tr>
                <tr>
                    <td>SYNTHETIC-1 SFT</td><td style="font-size:0.75rem; font-family: monospace;">PrimeIntellect/SYNTHETIC-1-SFT-Data</td><td>900K</td><td><span class="badge b-amber">Code</span> <span class="badge b-purple">STEM</span></td>
                    <td><span class="badge b-green">19.2K converted</span></td>
                </tr>
                <tr>
                    <td>ARC</td><td style="font-size:0.75rem; font-family: monospace;">allenai/ai2_arc</td><td>7.8K</td><td><span class="badge b-purple">Science</span></td>
                    <td><span class="badge b-green">1.1K converted</span></td>
                </tr>
                <tr>
                    <td>StrategyQA</td><td style="font-size:0.75rem; font-family: monospace;">wics/strategy-qa</td><td>2.8K</td><td><span class="badge b-purple">Science</span></td>
                    <td><span class="badge b-green">1.6K converted</span></td>
                </tr>
                <tr>
                    <td>ProofWriter</td><td style="font-size:0.75rem; font-family: monospace;">local</td><td>174K</td><td><span class="badge b-purple">Logic</span></td>
                    <td><span class="badge b-green">On disk</span></td>
                </tr>
                <tr>
                    <td>ProntoQA</td><td style="font-size:0.75rem; font-family: monospace;">local</td><td>300</td><td><span class="badge b-purple">Logic</span></td>
                    <td><span class="badge b-green">On disk</span></td>
                </tr>
                <tr>
                    <td>FOLIO</td><td style="font-size:0.75rem; font-family: monospace;">local</td><td>204</td><td><span class="badge b-purple">Logic</span></td>
                    <td><span class="badge b-green">On disk</span></td>
                </tr>
            </tbody>
        </table>
        </div>
    </div>
</div>

<!-- ===== STEP 3: LOGIC DOMAIN ===== -->
<div class="section">
    <div class="section-header">
        <div class="section-num sn-purple">3</div>
        <div class="section-title-text">Logic Domain &mdash; 30K Traces</div>
    </div>

    <!-- 3.1 ProofWriter -->
    <div class="card">
        <h3 style="font-size: 0.95rem; color: #7c3aed; margin-bottom: 0.5rem;">3.1 ProofWriter Gold Proof Conversion (~26.7K) <span class="badge b-green">Done</span></h3>
        <p>174K entries with gold proof trees, 3-class answers. <strong>Programmatic conversion</strong> achieved 92% success rate.</p>
        <ul class="task-list">
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">ProofWriter 3-class SFT generation (471 via LLM + 26.7K programmatic)</div>
                    <div class="task-desc">Programmatic: 26,689 entries. Perfect 3-class balance: 8,916 True / 8,901 False / 8,872 Unknown</div>
                </div>
            </li>
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">Created convert_proofwriter_proofs.py (1,692 lines)</div>
                    <div class="task-desc">Recursive proof tree parser, triple/rule mapping, bottom-up linearization, predicate &lt;logic&gt; generation</div>
                </div>
            </li>
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">CWA failure reasoning for Unknown entries</div>
                    <div class="task-desc">Explains why derivation fails under closed-world assumption</div>
                </div>
            </li>
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">Balanced selection: depth 1&ndash;7, 30K total</div>
                    <div class="task-desc">10K per label, balanced across depths. Excludes NatLang subset.</div>
                </div>
            </li>
        </ul>
        <div class="code-block">
<span class="comment">// ProofWriter proof field (input)</span>
[(((triple2 triple1 triple4) -> rule3))]

<span class="comment">// Converted output</span>
<span class="tag">&lt;step</span> <span class="attr">n="1" type="premise"</span><span class="tag">&gt;</span>
<span class="tag">&lt;text&gt;</span><span class="str">Dave is big.</span><span class="tag">&lt;/text&gt;</span>
<span class="tag">&lt;logic&gt;</span><span class="str">big(dave).</span><span class="tag">&lt;/logic&gt;</span>
<span class="tag">&lt;/step&gt;</span>
        </div>
    </div>

    <!-- 3.2 LogicBench -->
    <div class="card">
        <h3 style="font-size: 0.95rem; color: #7c3aed; margin-bottom: 0.5rem;">3.2 LogicBench Expansion (~8K)</h3>
        <ul class="task-list">
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">6,033 entries across 25 theories (prop + FOL + NM)</div>
                    <div class="task-desc">Generated with GPT-4o + SAT/NSFR/ASP verification</div>
                </div>
            </li>
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">Fixed 3 missing propositional theories</div>
                    <div class="task-desc">hypothetical_syllogism, material_implication, modus_tollens now included in Proof Bank v5</div>
                </div>
            </li>
            <li class="task-item">
                <div class="task-check check-todo">&middot;</div>
                <div class="task-content">
                    <div class="task-title">Generate portion without answer hint</div>
                    <div class="task-desc">Authentic reasoning instead of rationalization</div>
                </div>
            </li>
        </ul>
    </div>

    <!-- 3.3-3.7 Other logic -->
    <div class="card">
        <h3 style="font-size: 0.95rem; color: #7c3aed; margin-bottom: 0.5rem;">3.3&ndash;3.7 Additional Logic Sources</h3>
        <div class="table-wrap">
        <table>
            <thead><tr><th>Source</th><th>Target</th><th>Method</th><th>Answer Type</th><th>Status</th></tr></thead>
            <tbody>
                <tr>
                    <td>FOLIO (3.3)</td><td>~200</td><td>LLM generation + NSFR verify</td><td>Ternary</td>
                    <td><span class="badge b-green">44 done</span></td>
                </tr>
                <tr>
                    <td>ProntoQA (3.4)</td><td>~1K</td><td>Programmatic from gold CoT</td><td>Binary</td>
                    <td><span class="badge b-gray">Not started</span></td>
                </tr>
                <tr>
                    <td>EntailmentBank (3.5)</td><td>~1.8K</td><td>Parse entailment trees</td><td>Binary</td>
                    <td><span class="badge b-gray">Not started</span></td>
                </tr>
                <tr>
                    <td>RuleTaker (3.6)</td><td>~5K</td><td>Same as ProofWriter pipeline</td><td>Ternary</td>
                    <td><span class="badge b-gray">Not started</span></td>
                </tr>
                <tr>
                    <td>CLUTRR (3.7)</td><td>~2K</td><td>Convert relational chains</td><td>Relational</td>
                    <td><span class="badge b-gray">Not started</span></td>
                </tr>
            </tbody>
        </table>
        </div>
        <p style="font-size:0.82rem; color:#666; margin-top:0.5rem;">CLUTRR is especially interesting &mdash; relational answers (grandfather, uncle) break the yes/no pattern completely.</p>
    </div>
</div>

<!-- ===== STEP 4: MATH DOMAIN ===== -->
<div class="section">
    <div class="section-header">
        <div class="section-num sn-blue">4</div>
        <div class="section-title-text">Math Domain &mdash; 40K Traces</div>
    </div>
    <div class="card">
        <h3 style="font-size: 0.95rem; color: #2563eb; margin-bottom: 0.5rem;">4.1 OpenR1-Math-220k Conversion (~50K) <span class="badge b-green">Done</span></h3>
        <p>50K entries converted via chunk-based parser in 42 seconds. SymPy approach abandoned (traces are free-form, not structured equations).</p>
        <ul class="task-list">
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">Created convert_math_traces.py (1,215 lines)</div>
                    <div class="task-desc">SymPy verification + heuristic parsing. Then pivoted to chunk-based converter (99.9% pass rate, instant)</div>
                </div>
            </li>
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">50,053 entries converted from OpenR1-Math</div>
                    <div class="task-desc">Chunk-based: 42 seconds for 50K entries. High quality multi-step reasoning with equations in &lt;logic&gt;</div>
                </div>
            </li>
        </ul>
        <div class="code-block">
<span class="tag">&lt;step</span> <span class="attr">n="1" type="premise"</span><span class="tag">&gt;</span>
<span class="tag">&lt;text&gt;</span><span class="str">We are given the equation 3x + 5 = 20.</span><span class="tag">&lt;/text&gt;</span>
<span class="tag">&lt;logic&gt;</span><span class="str">3*x + 5 = 20</span><span class="tag">&lt;/logic&gt;</span>
<span class="tag">&lt;/step&gt;</span>
<span class="tag">&lt;step</span> <span class="attr">n="2" type="derived" from="1"</span><span class="tag">&gt;</span>
<span class="tag">&lt;text&gt;</span><span class="str">Subtract 5 from both sides.</span><span class="tag">&lt;/text&gt;</span>
<span class="tag">&lt;logic&gt;</span><span class="str">3*x = 15</span><span class="tag">&lt;/logic&gt;</span>
<span class="tag">&lt;/step&gt;</span>
<span class="tag">&lt;step</span> <span class="attr">n="3" type="derived" from="2"</span><span class="tag">&gt;</span>
<span class="tag">&lt;text&gt;</span><span class="str">Divide both sides by 3.</span><span class="tag">&lt;/text&gt;</span>
<span class="tag">&lt;logic&gt;</span><span class="str">x = 5</span><span class="tag">&lt;/logic&gt;</span>
<span class="tag">&lt;/step&gt;</span>
        </div>

        <h3 style="font-size: 0.95rem; color: #2563eb; margin: 1.2rem 0 0.5rem;">4.2 GSM8K (~5K) &amp; 4.3 MATH (~5K)</h3>
        <ul class="task-list">
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">GSM8K: 6,483 entries converted</div>
                    <div class="task-desc">Parsed annotated solution steps with SymPy verification. Easier difficulty for curriculum baseline.</div>
                </div>
            </li>
            <li class="task-item">
                <div class="task-check check-todo">&middot;</div>
                <div class="task-content">
                    <div class="task-title">MATH: Convert competition problems + SymPy verify</div>
                    <div class="task-desc">12.5K problems, harder difficulty &mdash; upper range. Not yet started.</div>
                </div>
            </li>
        </ul>
    </div>
</div>

<!-- ===== STEP 5: CODE DOMAIN ===== -->
<div class="section">
    <div class="section-header">
        <div class="section-num sn-amber">5</div>
        <div class="section-title-text">Code Domain &mdash; 15K Traces</div>
    </div>
    <div class="card">
        <ul class="task-list">
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">5.1 SYNTHETIC-1 code conversion (7,553 entries)</div>
                    <div class="task-desc">convert_code_traces.py (447 lines). 91% pass rate from 8,265 input. Sandboxed execution + restricted namespace.</div>
                    <div class="task-badges"><span class="badge b-green">Done</span></div>
                </div>
            </li>
            <li class="task-item">
                <div class="task-check check-todo">&middot;</div>
                <div class="task-content">
                    <div class="task-title">5.2 CodeContests / Apps (~5K)</div>
                    <div class="task-desc">Competition programming &rarr; step-by-step sub-operations. Not yet started.</div>
                </div>
            </li>
        </ul>
    </div>
</div>

<!-- ===== STEP 6: SCIENCE DOMAIN ===== -->
<div class="section">
    <div class="section-header">
        <div class="section-num sn-teal">6</div>
        <div class="section-title-text">Science / STEM Domain &mdash; 15K Traces</div>
    </div>
    <div class="card">
        <ul class="task-list">
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">6.1 SYNTHETIC-1 STEM conversion (1,669 entries)</div>
                    <div class="task-desc">StackExchange-sourced. 99.9% pass rate from 1,671 input.</div>
                </div>
            </li>
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">6.2 ARC Science (1,118 entries)</div>
                    <div class="task-desc">AI2 Reasoning Challenge, multiple-choice format converted.</div>
                </div>
            </li>
            <li class="task-item task-done">
                <div class="task-check check-done">&#10003;</div>
                <div class="task-content">
                    <div class="task-title">6.3 StrategyQA (1,603 entries)</div>
                    <div class="task-desc">Multi-hop yes/no with gold sub-question decomposition converted to steps.</div>
                </div>
            </li>
        </ul>
    </div>
</div>

<!-- ===== STEP 7: ASSEMBLY ===== -->
<div class="section">
    <div class="section-header">
        <div class="section-num sn-indigo">7</div>
        <div class="section-title-text">Assembly &amp; Quality Control</div>
    </div>
    <div class="card">
        <p><code>experiments/assemble_proof_bank.py</code> &mdash; merge, validate, balance, and output final dataset.</p>

        <h3 style="font-size: 0.92rem; color: #16213e; margin: 1rem 0 0.5rem;">Quality Gates (all must pass)</h3>
        <div class="verify-grid">
            <div class="verify-card" style="border-left-color: #2563eb;">
                <h4>Format</h4>
                <p>Valid &lt;think&gt; + &lt;step&gt; structure with &lt;text&gt; and &lt;logic&gt; sub-tags</p>
            </div>
            <div class="verify-card" style="border-left-color: #7c3aed;">
                <h4>Parse</h4>
                <p>Successfully parsed by <code>parse_think_steps()</code></p>
            </div>
            <div class="verify-card" style="border-left-color: #16a34a;">
                <h4>Verification</h4>
                <p>&ge; 60% of derived steps pass domain-specific verification</p>
            </div>
            <div class="verify-card" style="border-left-color: #d97706;">
                <h4>Answer</h4>
                <p>Final answer present and correctly formatted for its type</p>
            </div>
            <div class="verify-card" style="border-left-color: #e11d48;">
                <h4>Length</h4>
                <p>2+ derived steps, &le; 20 total steps</p>
            </div>
        </div>

        <h3 style="font-size: 0.92rem; color: #16213e; margin: 1rem 0 0.5rem;">Metadata Schema</h3>
        <div class="code-block">
{
  <span class="str">"id"</span>: <span class="str">"pb_math_001234"</span>,
  <span class="str">"domain"</span>: <span class="str">"math"</span>,
  <span class="str">"source"</span>: <span class="str">"openr1_math"</span>,
  <span class="str">"difficulty"</span>: <span class="str">"medium"</span>,
  <span class="str">"answer_type"</span>: <span class="str">"numeric"</span>,
  <span class="str">"reasoning_depth"</span>: <span class="attr">5</span>,
  <span class="str">"num_steps"</span>: <span class="attr">7</span>,
  <span class="str">"verification_method"</span>: <span class="str">"sympy"</span>,
  <span class="str">"verification_score"</span>: <span class="attr">0.95</span>,
  <span class="str">"system_prompt"</span>: <span class="str">"..."</span>,
  <span class="str">"user_prompt"</span>: <span class="str">"..."</span>,
  <span class="str">"completion"</span>: <span class="str">"&lt;think&gt;...&lt;/think&gt;\nAnswer: 42"</span>
}
        </div>

        <h3 style="font-size: 0.92rem; color: #16213e; margin: 1rem 0 0.5rem;">Balancing Strategy</h3>
        <p>Within each domain: <strong>difficulty</strong> (easy 30% / medium 40% / hard 30%), <strong>answer types</strong> (within logic: binary, ternary, relational, proof), <strong>source datasets</strong> (no single source > 50% of domain).</p>
    </div>
</div>

<!-- ===== STEP 8: TRAINING ===== -->
<div class="section">
    <div class="section-header">
        <div class="section-num sn-rose">8</div>
        <div class="section-title-text">Training Pipeline</div>
    </div>
    <div class="card">
        <h3 style="font-size: 0.92rem; color: #16213e; margin-bottom: 0.5rem;">SFT on Proof Bank</h3>
        <div class="code-block">
<span class="comment"># experiments/configs/deepseek_sft_proof_bank.yaml</span>
dataset: data/proof_bank/proof_bank_v1.jsonl
model: deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
epochs: <span class="attr">2</span>
lr: <span class="attr">1.5e-4</span>
max_seq_len: <span class="attr">10240</span>
train_on_responses_only: <span class="attr">true</span>
        </div>

        <h3 style="font-size: 0.92rem; color: #16213e; margin: 1rem 0 0.5rem;">GRPO with Multi-Domain Verification</h3>
        <p>Domain-aware reward dispatch &mdash; each training example's domain tag selects the verification backend:</p>
        <div class="verify-grid">
            <div class="verify-card" style="border-left-color: #7c3aed;">
                <h4>Logic</h4>
                <p>SAT / ASP / NSFR</p>
            </div>
            <div class="verify-card" style="border-left-color: #2563eb;">
                <h4>Math</h4>
                <p>SymPy algebraic verification</p>
            </div>
            <div class="verify-card" style="border-left-color: #d97706;">
                <h4>Code</h4>
                <p>Sandboxed Python execution</p>
            </div>
            <div class="verify-card" style="border-left-color: #0d9488;">
                <h4>Science</h4>
                <p>NLI entailment + LLM judge</p>
            </div>
        </div>
    </div>
</div>

<!-- ===== IMPLEMENTATION PRIORITY ===== -->
<div class="section">
    <div class="section-header">
        <div class="section-num sn-slate">!</div>
        <div class="section-title-text">Implementation Priority &amp; Critical Path</div>
    </div>
    <div class="card">
        <h3 style="font-size: 0.92rem; color: #16213e; margin-bottom: 0.8rem;">Critical Path</h3>
        <div class="critical-path">
            <div class="cp-node cp-done">#1 Prompt System</div>
            <div class="cp-arrow">&rarr;</div>
            <div class="cp-node cp-done">#3 ProofWriter Conv.</div>
            <div class="cp-arrow">&rarr;</div>
            <div class="cp-node cp-done">#6 OpenR1-Math Conv.</div>
            <div class="cp-arrow">&rarr;</div>
            <div class="cp-node cp-done">#11 Assembly</div>
            <div class="cp-arrow">&rarr;</div>
            <div class="cp-node cp-active">#12 SFT</div>
            <div class="cp-arrow">&rarr;</div>
            <div class="cp-node cp-todo">#13 GRPO</div>
        </div>
        <p style="font-size:0.82rem; color:#666; margin: 0.8rem 0 0.5rem;">Critical path nearly complete. SFT v1 (26K) and v5 (80K balanced) training in progress on SLURM. GRPO with multi-domain reward dispatch is the final step.</p>

        <div class="table-wrap">
        <table>
            <thead>
                <tr><th>#</th><th>Task</th><th>Files</th><th>Effort</th><th>Deps</th><th>Status</th></tr>
            </thead>
            <tbody>
                <tr style="background: #f0fdf4;">
                    <td><strong>1</strong></td><td><strong>Multi-answer prompt system</strong></td>
                    <td style="font-size:0.75rem; font-family: monospace;">answer_instructions.py, think_cot_prompt.txt</td>
                    <td>1 day</td><td>None</td>
                    <td><span class="badge b-green">Done</span></td>
                </tr>
                <tr style="background: #f0fdf4;">
                    <td><strong>2</strong></td><td><strong>Dataset downloader</strong></td>
                    <td style="font-size:0.75rem; font-family: monospace;">download_datasets.py</td>
                    <td>0.5 day</td><td>None</td>
                    <td><span class="badge b-green">Done</span></td>
                </tr>
                <tr style="background: #f0fdf4;">
                    <td><strong>3</strong></td><td><strong>ProofWriter proof converter</strong></td>
                    <td style="font-size:0.75rem; font-family: monospace;">convert_proofwriter_proofs.py</td>
                    <td>2-3 days</td><td>None</td>
                    <td><span class="badge b-green">Done (26.7K)</span></td>
                </tr>
                <tr style="background: #f0fdf4;">
                    <td>4</td><td>FOLIO + ProntoQA expansion</td>
                    <td style="font-size:0.75rem; font-family: monospace;">generate_sft_data.py</td>
                    <td>1 day</td><td>#1</td>
                    <td><span class="badge b-green">Done</span></td>
                </tr>
                <tr>
                    <td>5</td><td>EntailmentBank + RuleTaker + CLUTRR</td>
                    <td style="font-size:0.75rem; font-family: monospace;">convert_logic_traces.py</td>
                    <td>2 days</td><td>#2</td>
                    <td><span class="badge b-gray">Deferred</span></td>
                </tr>
                <tr style="background: #f0fdf4;">
                    <td><strong>6</strong></td><td><strong>OpenR1-Math conversion</strong></td>
                    <td style="font-size:0.75rem; font-family: monospace;">convert_math_traces.py</td>
                    <td>3-4 days</td><td>#1, #2</td>
                    <td><span class="badge b-green">Done (50K)</span></td>
                </tr>
                <tr style="background: #f0fdf4;">
                    <td>7</td><td>GSM8K + MATH conversion</td>
                    <td style="font-size:0.75rem; font-family: monospace;">convert_math_traces.py</td>
                    <td>1-2 days</td><td>#6</td>
                    <td><span class="badge b-green">GSM8K done (6.5K)</span></td>
                </tr>
                <tr style="background: #f0fdf4;">
                    <td>8</td><td>SYNTHETIC-1 code conversion</td>
                    <td style="font-size:0.75rem; font-family: monospace;">convert_code_traces.py</td>
                    <td>2 days</td><td>#1, #2</td>
                    <td><span class="badge b-green">Done (7.5K)</span></td>
                </tr>
                <tr style="background: #f0fdf4;">
                    <td>9</td><td>Science/STEM conversion</td>
                    <td style="font-size:0.75rem; font-family: monospace;">convert_science_traces.py</td>
                    <td>2 days</td><td>#1, #2</td>
                    <td><span class="badge b-green">Done (4.4K)</span></td>
                </tr>
                <tr style="background: #f0fdf4;">
                    <td>10</td><td>Reward function updates</td>
                    <td style="font-size:0.75rem; font-family: monospace;">reward.py</td>
                    <td>1 day</td><td>#1</td>
                    <td><span class="badge b-green">Done (45 tests pass)</span></td>
                </tr>
                <tr style="background: #f0fdf4;">
                    <td><strong>11</strong></td><td><strong>Assembly + balancing</strong></td>
                    <td style="font-size:0.75rem; font-family: monospace;">assemble_proof_bank.py</td>
                    <td>1 day</td><td>#3-9</td>
                    <td><span class="badge b-green">Done (v5: 111K)</span></td>
                </tr>
                <tr style="background: #fefce8;">
                    <td><strong>12</strong></td><td><strong>SFT training</strong></td>
                    <td style="font-size:0.75rem; font-family: monospace;">configs/</td>
                    <td>0.5 day</td><td>#11</td>
                    <td><span class="badge b-blue">Running (v1+v5)</span></td>
                </tr>
                <tr style="background: #fefce8;">
                    <td><strong>13</strong></td><td><strong>GRPO multi-domain reward</strong></td>
                    <td style="font-size:0.75rem; font-family: monospace;">train_experiment.py, reward.py</td>
                    <td>1-2 days</td><td>#10, #12</td>
                    <td><span class="badge b-gray">Waiting on SFT</span></td>
                </tr>
            </tbody>
        </table>
        </div>
    </div>
</div>

<!-- ===== VERIFICATION PLAN ===== -->
<div class="section">
    <div class="section-header">
        <div class="section-num sn-green">V</div>
        <div class="section-title-text">Verification Plan</div>
    </div>
    <div class="card">
        <ul class="task-list">
            <li class="task-item">
                <div class="task-check check-todo">&middot;</div>
                <div class="task-content">
                    <div class="task-title">Format test: 100 random traces per domain parse correctly</div>
                    <div class="task-desc">Run parse_think_steps() on random sample from each domain</div>
                </div>
            </li>
            <li class="task-item">
                <div class="task-check check-todo">&middot;</div>
                <div class="task-content">
                    <div class="task-title">Domain verification: 50 traces per domain through verification backend</div>
                    <div class="task-desc">SAT for logic, SymPy for math, sandbox for code, NLI for science</div>
                </div>
            </li>
            <li class="task-item">
                <div class="task-check check-todo">&middot;</div>
                <div class="task-content">
                    <div class="task-title">Existing test suite passes after reward.py changes</div>
                    <div class="task-desc">Run test_consistency_reward.py (40 tests)</div>
                </div>
            </li>
            <li class="task-item">
                <div class="task-check check-todo">&middot;</div>
                <div class="task-content">
                    <div class="task-title">SFT smoke test: 50 steps on small subset, loss decreases</div>
                    <div class="task-desc">Verify formatted outputs after short training</div>
                </div>
            </li>
            <li class="task-item">
                <div class="task-check check-todo">&middot;</div>
                <div class="task-content">
                    <div class="task-title">Eval regression: LogicBench does NOT regress, FOLIO IMPROVES</div>
                    <div class="task-desc">Primary success metric for the Proof Bank expansion</div>
                </div>
            </li>
            <li class="task-item">
                <div class="task-check check-todo">&middot;</div>
                <div class="task-content">
                    <div class="task-title">Math eval: Baseline GSM8K/MATH performance after SFT</div>
                    <div class="task-desc">Cross-domain transfer evaluation</div>
                </div>
            </li>
        </ul>
    </div>
</div>

<div class="footer">
    RAILS &middot; Proof Bank &middot; Last updated: <span id="last-updated"></span>
    <br>Source: <a href="https://github.com/hs40vahe/ProofContinuity">ProofContinuity</a>
</div>
<script>
document.getElementById("last-updated").textContent = new Date().toLocaleDateString("en-US", {
    year: "numeric",
    month: "long",
    day: "numeric",
});

const EXPLORER_DATA_PATH = "proof_tree_explorer_data.json";
const PILOT_TARGET = 5000;
const DATASET_DOMAIN_MAP = {
    logicbench_propositional: "logic",
    logicbench_fol_nsfr: "logic",
    logicbench_fol_asp: "logic",
    logicbench_nm_asp: "logic",
    logicbench_nm_asp_extra: "logic",
    folio: "logic",
    proofwriter: "logic",
    gsm8k: "math",
    openr1_math: "math",
    math_hendrycks: "math",
    synthetic1_code: "code",
    mbpp: "code",
    cruxeval: "code",
};
const explorerState = {
    data: null,
    filtered: [],
    activeId: null,
};

function esc(text) {
    return String(text || "")
        .replace(/&/g, "&amp;")
        .replace(/</g, "&lt;")
        .replace(/>/g, "&gt;");
}

function formatInt(value) {
    return Number(value || 0).toLocaleString("en-US");
}

function formatPct(value) {
    return `${Number(value || 0).toFixed(1)}%`;
}

function formatDateTime(isoText) {
    if (!isoText) return "n/a";
    const dt = new Date(isoText);
    if (Number.isNaN(dt.getTime())) return isoText;
    return dt.toLocaleString("en-US", {
        year: "numeric",
        month: "short",
        day: "numeric",
        hour: "2-digit",
        minute: "2-digit",
    });
}

function setText(id, text) {
    const el = document.getElementById(id);
    if (el) el.textContent = text;
}

function domainForDataset(datasetKey) {
    return DATASET_DOMAIN_MAP[datasetKey] || "other";
}

function buildPilotSummary(data) {
    const records = Array.isArray(data.records) ? data.records : [];
    const datasets = Array.isArray(data.datasets) ? data.datasets : [];
    const countByDataset = new Map();
    let totalSteps = 0;
    let parseSuccess = 0;
    let minSteps = Number.POSITIVE_INFINITY;
    let maxSteps = 0;

    records.forEach((r) => {
        const key = r.dataset || "unknown";
        const steps = Number(r.num_steps) || 0;
        countByDataset.set(key, (countByDataset.get(key) || 0) + 1);
        totalSteps += steps;
        minSteps = Math.min(minSteps, steps);
        maxSteps = Math.max(maxSteps, steps);
        if (r.validation && r.validation.parse_success === true) parseSuccess += 1;
    });

    const datasetRows = datasets.map((d) => ({
        key: d.key,
        label: d.label || d.key,
        source_file: d.source_file || "",
        count: countByDataset.get(d.key) || Number(d.count) || 0,
        domain: domainForDataset(d.key),
    }));

    countByDataset.forEach((count, key) => {
        if (!datasetRows.some((row) => row.key === key)) {
            datasetRows.push({
                key,
                label: key,
                source_file: "",
                count,
                domain: domainForDataset(key),
            });
        }
    });

    datasetRows.sort((a, b) => b.count - a.count);
    const totalsByDomain = { logic: 0, math: 0, code: 0, other: 0 };
    datasetRows.forEach((row) => {
        totalsByDomain[row.domain] = (totalsByDomain[row.domain] || 0) + row.count;
    });

    const total = records.length;
    return {
        total,
        avgSteps: total ? totalSteps / total : 0,
        parseRate: total ? (100 * parseSuccess) / total : 0,
        minSteps: Number.isFinite(minSteps) ? minSteps : 0,
        maxSteps,
        datasetRows,
        totalsByDomain,
        activeDomains: Object.values(totalsByDomain).filter((x) => x > 0).length,
        targetPct: PILOT_TARGET ? (100 * total) / PILOT_TARGET : 0,
    };
}

function renderPilotSummary(data) {
    const summary = buildPilotSummary(data);
    const total = summary.total;
    const logic = summary.totalsByDomain.logic || 0;
    const math = summary.totalsByDomain.math || 0;
    const code = summary.totalsByDomain.code || 0;
    const logicPct = total ? (100 * logic) / total : 0;
    const mathPct = total ? (100 * math) / total : 0;
    const codePct = total ? (100 * code) / total : 0;

    setText("pb-stat-total", formatInt(total));
    setText("pb-stat-progress", formatPct(summary.targetPct));
    setText("pb-stat-datasets", String(summary.datasetRows.length));
    setText("pb-stat-domains", String(summary.activeDomains));
    setText("pb-stat-avg-steps", summary.avgSteps.toFixed(1));
    setText("pb-generated-at", formatDateTime(data.generated_at_utc));
    setText("pb-legend-logic", `Logic: ${formatInt(logic)} (${formatPct(logicPct)})`);
    setText("pb-legend-math", `Math: ${formatInt(math)} (${formatPct(mathPct)})`);
    setText("pb-legend-code", `Code: ${formatInt(code)} (${formatPct(codePct)})`);

    setText("pb-ctx-datasets", String(summary.datasetRows.length));
    setText("pb-ctx-min-steps", String(summary.minSteps));
    setText("pb-ctx-max-steps", String(summary.maxSteps));
    setText("pb-ctx-parse", formatPct(summary.parseRate));

    const logicSeg = document.getElementById("pb-seg-logic");
    if (logicSeg) {
        logicSeg.style.width = `${logicPct}%`;
        logicSeg.textContent = `Logic ${formatPct(logicPct)}`;
    }
    const mathSeg = document.getElementById("pb-seg-math");
    if (mathSeg) {
        mathSeg.style.width = `${mathPct}%`;
        mathSeg.textContent = `Math ${formatPct(mathPct)}`;
    }
    const codeSeg = document.getElementById("pb-seg-code");
    if (codeSeg) {
        codeSeg.style.width = `${codePct}%`;
        codeSeg.textContent = `Code ${formatPct(codePct)}`;
    }

    const tableBody = document.getElementById("pb-dataset-table");
    if (tableBody) {
        const rows = summary.datasetRows
            .map((row) => {
                const share = total ? (100 * row.count) / total : 0;
                const rowClass = row.domain === "logic"
                    ? "domain-logic"
                    : row.domain === "math"
                        ? "domain-math"
                        : row.domain === "code"
                            ? "domain-code"
                            : "";
                return `
                    <tr class="${rowClass}">
                        <td>${esc(row.label)}</td>
                        <td>${esc(row.domain)}</td>
                        <td>${esc(formatInt(row.count))}</td>
                        <td>${esc(formatPct(share))}</td>
                        <td style="font-size:0.75rem; font-family: monospace;">${esc(row.source_file || "-")}</td>
                        <td><span class="badge b-green">Loaded</span></td>
                    </tr>
                `;
            })
            .join("");
        tableBody.innerHTML = `${rows}
            <tr class="row-total">
                <td>Total</td>
                <td>${esc(summary.activeDomains.toString())} active</td>
                <td>${esc(formatInt(total))}</td>
                <td>100%</td>
                <td></td>
                <td></td>
            </tr>
        `;
    }

    const logicSources = summary.datasetRows
        .filter((row) => row.domain === "logic" && row.count > 0)
        .map((row) => `${row.label} (${formatInt(row.count)})`)
        .join(" + ");
    const mathSources = summary.datasetRows
        .filter((row) => row.domain === "math" && row.count > 0)
        .map((row) => `${row.label} (${formatInt(row.count)})`)
        .join(" + ");
    const codeSources = summary.datasetRows
        .filter((row) => row.domain === "code" && row.count > 0)
        .map((row) => `${row.label} (${formatInt(row.count)})`)
        .join(" + ");

    setText("pb-domain-logic-current", `Current: ${formatInt(logic)} (${formatPct(logicPct)})`);
    setText("pb-domain-math-current", `Current: ${formatInt(math)} (${formatPct(mathPct)})`);
    setText("pb-domain-code-current", `Current: ${formatInt(code)} (${formatPct(codePct)})`);
    setText("pb-domain-logic-sources", logicSources || "No logic traces loaded");
    setText("pb-domain-math-sources", mathSources || "No math traces loaded");
    setText("pb-domain-code-sources", codeSources || "No code traces loaded");

    const logicFill = document.getElementById("pb-domain-logic-fill");
    if (logicFill) logicFill.style.width = `${logicPct}%`;
    const mathFill = document.getElementById("pb-domain-math-fill");
    if (mathFill) mathFill.style.width = `${mathPct}%`;
    const codeFill = document.getElementById("pb-domain-code-fill");
    if (codeFill) codeFill.style.width = `${codePct}%`;
}

function getFilterValues() {
    return {
        dataset: document.getElementById("dataset-filter").value,
        query: document.getElementById("search-filter").value.trim().toLowerCase(),
        minSteps: Math.max(0, Number(document.getElementById("min-steps").value) || 0),
        limit: Math.max(1, Number(document.getElementById("limit-records").value) || 120),
    };
}

function hydrateDatasetSelect() {
    const select = document.getElementById("dataset-filter");
    const options = explorerState.data.datasets
        .map((d) => `<option value="${esc(d.key)}">${esc(d.label)} (${d.count})</option>`)
        .join("");
    select.insertAdjacentHTML("beforeend", options);
}

function applyFilters() {
    if (!explorerState.data) return;
    const f = getFilterValues();
    const records = explorerState.data.records.filter((r) => {
        if (f.dataset !== "all" && r.dataset !== f.dataset) return false;
        if ((r.num_steps || 0) < f.minSteps) return false;
        if (!f.query) return true;
        const haystack = [
            r.id,
            r.dataset,
            r.theory,
            r.context,
            r.question,
            r.expected_answer,
            (r.steps || []).map((s) => `${s.text} ${s.logic}`).join(" "),
        ].join(" ").toLowerCase();
        return haystack.includes(f.query);
    });

    explorerState.filtered = records.slice(0, f.limit);
    if (!explorerState.filtered.some((x) => x.id === explorerState.activeId)) {
        explorerState.activeId = explorerState.filtered.length ? explorerState.filtered[0].id : null;
    }
    renderList();
    renderDetail();
    renderMeta(records.length, explorerState.filtered.length);
}

function renderMeta(totalMatches, shown) {
    const total = explorerState.data.records.length;
    document.getElementById("explorer-meta").textContent =
        `Loaded ${total} traces across ${explorerState.data.datasets.length} datasets. ` +
        `Showing ${shown} / ${totalMatches} matches.`;
}

function renderList() {
    const root = document.getElementById("example-list");
    if (!explorerState.filtered.length) {
        root.innerHTML = '<div class="no-results">No traces match current filters.</div>';
        return;
    }
    root.innerHTML = explorerState.filtered
        .map((r) => {
            const active = r.id === explorerState.activeId ? " active" : "";
            const v = r.validation || {};
            return `
                <div class="example-row${active}" data-id="${esc(r.id)}">
                    <div class="row-id">${esc(r.id)}</div>
                    <div class="row-meta">
                        <span class="row-chip chip-dataset">${esc(r.dataset)}</span>
                        <span class="row-chip chip-steps">${esc(r.num_steps)} steps</span>
                        <span class="row-chip chip-verify">${esc(v.verification_method || "n/a")}</span>
                    </div>
                </div>
            `;
        })
        .join("");
    root.querySelectorAll(".example-row").forEach((el) => {
        el.addEventListener("click", () => {
            explorerState.activeId = el.getAttribute("data-id");
            renderList();
            renderDetail();
        });
    });
}

function renderDetail() {
    const root = document.getElementById("example-detail");
    const rec = explorerState.filtered.find((r) => r.id === explorerState.activeId);
    if (!rec) {
        root.innerHTML = '<div class="no-results">Select an example to inspect its proof tree.</div>';
        return;
    }
    const v = rec.validation || {};
    const stepsHtml = (rec.steps || []).length
        ? rec.steps.map((s) => `
            <div class="proof-step ${esc(s.type || "derived")}">
                <div class="proof-head">Step ${esc(s.n || "?")} &middot; ${esc(s.type || "derived")}${s.from ? ` &middot; from: ${esc(s.from)}` : ""}</div>
                <div class="proof-text">${esc(s.text || "(no text)")}</div>
                <div class="proof-logic">${esc(s.logic || "(no logic)")}</div>
            </div>
        `).join("")
        : '<div class="no-results">No parsed <step> tags found in this completion.</div>';

    root.innerHTML = `
        <div class="detail-title">${esc(rec.id)}</div>
        <div class="detail-meta">
            Dataset: ${esc(rec.dataset)} &middot;
            Theory: ${esc(rec.theory)} &middot;
            Expected: ${esc(rec.expected_answer)} &middot;
            Steps: ${esc(rec.num_steps)} &middot;
            Verify: ${esc(v.verification_method || "n/a")} &middot;
            Score: ${esc(v.code_score ?? v.consistency_score ?? "n/a")}
        </div>
        <div class="detail-prompt"><strong>Context</strong>\n${esc(rec.context || "")}</div>
        <div class="detail-prompt"><strong>Question</strong>\n${esc(rec.question || "")}</div>
        <div style="font-size:0.82rem; color:#475569; font-weight:600; margin-bottom:0.45rem;">Proof Tree</div>
        ${stepsHtml}
    `;
}

async function initExplorer() {
    try {
        const res = await fetch(EXPLORER_DATA_PATH);
        if (!res.ok) throw new Error(`HTTP ${res.status}`);
        explorerState.data = await res.json();
        renderPilotSummary(explorerState.data);
        hydrateDatasetSelect();
        ["dataset-filter", "search-filter", "min-steps", "limit-records"].forEach((id) => {
            document.getElementById(id).addEventListener("input", applyFilters);
            document.getElementById(id).addEventListener("change", applyFilters);
        });
        applyFilters();
    } catch (err) {
        document.getElementById("explorer-meta").textContent =
            `Failed to load explorer data (${err.message}).`;
        document.getElementById("example-list").innerHTML =
            '<div class="no-results">Could not load proof_tree_explorer_data.json</div>';
    }
}

initExplorer();
</script>

</body>
</html>
