<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>RAILS â€” Transfer Evaluation: SARA &amp; LSAT</title>
<style>
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body { font-family: 'Segoe UI', system-ui, -apple-system, sans-serif; background: #f8f9fa; color: #1a1a2e; line-height: 1.6; padding: 2rem; max-width: 1100px; margin: 0 auto; }
    a { color: #2563eb; text-decoration: none; }
    a:hover { text-decoration: underline; }
    h1 { font-size: 1.8rem; margin-bottom: 0.3rem; color: #16213e; }
    .subtitle { color: #666; font-size: 0.95rem; margin-bottom: 1.5rem; }
    .back-link { display: inline-block; margin-bottom: 1.5rem; font-size: 0.9rem; }

    /* Summary cards */
    .key-finding { background: linear-gradient(135deg, #eff6ff, #f0f4ff); border-radius: 12px; padding: 1.5rem; margin-bottom: 2rem; border-left: 4px solid #2563eb; }
    .key-finding h2 { font-size: 1.1rem; color: #16213e; margin-bottom: 0.6rem; }
    .key-finding p { font-size: 0.9rem; color: #444; }
    .key-finding .highlight { font-weight: 700; color: #2563eb; }

    /* Benchmark description */
    .benchmarks { display: grid; grid-template-columns: 1fr 1fr; gap: 1.2rem; margin-bottom: 2rem; }
    .benchmark-card { background: white; border-radius: 12px; padding: 1.3rem; box-shadow: 0 1px 3px rgba(0,0,0,0.08); }
    .benchmark-card h3 { font-size: 1rem; color: #16213e; margin-bottom: 0.4rem; }
    .benchmark-card .meta { font-size: 0.8rem; color: #888; margin-bottom: 0.5rem; }
    .benchmark-card p { font-size: 0.85rem; color: #555; }
    .benchmark-card .badge { display: inline-block; padding: 0.15rem 0.5rem; border-radius: 20px; font-size: 0.72rem; font-weight: 600; margin-right: 0.3rem; }
    .badge-blue { background: #e0e7ff; color: #3730a3; }
    .badge-green { background: #dcfce7; color: #166534; }
    .badge-amber { background: #fef3c7; color: #92400e; }

    /* Tables */
    .table-section { background: white; border-radius: 12px; padding: 1.5rem; margin-bottom: 2rem; box-shadow: 0 1px 3px rgba(0,0,0,0.08); }
    .table-section h2 { font-size: 1.15rem; color: #16213e; margin-bottom: 0.3rem; }
    .table-section .table-note { font-size: 0.82rem; color: #888; margin-bottom: 1rem; }
    table { width: 100%; border-collapse: collapse; font-size: 0.85rem; }
    th { background: #f1f5f9; padding: 0.6rem 0.8rem; text-align: left; font-weight: 600; color: #475569; border-bottom: 2px solid #e2e8f0; }
    td { padding: 0.55rem 0.8rem; border-bottom: 1px solid #f1f5f9; }
    tr:hover td { background: #f8fafc; }
    .num { text-align: right; font-variant-numeric: tabular-nums; }
    .best { font-weight: 700; color: #16a34a; }
    .model-base { color: #6b7280; }
    .model-sft { color: #7c3aed; }
    .model-grpo { color: #2563eb; font-weight: 600; }
    .delta { font-size: 0.75rem; font-weight: 600; }
    .delta-up { color: #16a34a; }
    .delta-down { color: #dc2626; }

    /* Qualitative examples */
    .examples-section { margin-bottom: 2rem; }
    .examples-section h2 { font-size: 1.15rem; color: #16213e; margin-bottom: 0.5rem; }
    .examples-section .section-note { font-size: 0.82rem; color: #888; margin-bottom: 1rem; }

    .example-card { background: white; border-radius: 12px; padding: 1.5rem; margin-bottom: 1.5rem; box-shadow: 0 1px 3px rgba(0,0,0,0.08); }
    .example-card h3 { font-size: 1rem; color: #16213e; margin-bottom: 0.5rem; }
    .example-meta { font-size: 0.8rem; color: #888; margin-bottom: 0.8rem; }
    .example-prompt { background: #f8f9fa; border-radius: 8px; padding: 1rem; margin-bottom: 1rem; font-size: 0.85rem; color: #333; border-left: 3px solid #94a3b8; }
    .example-prompt strong { color: #16213e; display: block; margin-bottom: 0.3rem; font-size: 0.8rem; }

    .response-grid { display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 1rem; }
    @media (max-width: 1000px) {
        .response-grid { grid-template-columns: 1fr; }
        .benchmarks { grid-template-columns: 1fr; }
    }

    .response-box { border-radius: 8px; padding: 1rem; font-size: 0.82rem; font-family: 'Consolas', 'Monaco', monospace; white-space: pre-wrap; word-break: break-word; overflow: auto; max-height: 400px; }
    .response-box .box-header { font-family: 'Segoe UI', sans-serif; font-weight: 700; font-size: 0.85rem; margin-bottom: 0.5rem; display: flex; justify-content: space-between; align-items: center; }
    .response-correct { background: #f0fdf4; border: 1px solid #bbf7d0; }
    .response-correct .box-header { color: #166534; }
    .response-wrong { background: #fef2f2; border: 1px solid #fecaca; }
    .response-wrong .box-header { color: #991b1b; }
    .response-neutral { background: #f8f9fa; border: 1px solid #e5e7eb; }
    .response-neutral .box-header { color: #374151; }
    .verdict { font-size: 0.75rem; font-weight: 600; padding: 0.1rem 0.4rem; border-radius: 10px; }
    .verdict-correct { background: #dcfce7; color: #166534; }
    .verdict-wrong { background: #fecaca; color: #991b1b; }

    .step-tag { color: #7c3aed; font-weight: 600; }
    .logic-tag { color: #0369a1; }

    /* Analysis section */
    .analysis { background: white; border-radius: 12px; padding: 1.5rem; margin-bottom: 2rem; box-shadow: 0 1px 3px rgba(0,0,0,0.08); }
    .analysis h2 { font-size: 1.15rem; color: #16213e; margin-bottom: 0.8rem; }
    .analysis h3 { font-size: 0.95rem; color: #475569; margin-top: 1rem; margin-bottom: 0.4rem; }
    .analysis p, .analysis li { font-size: 0.88rem; color: #555; margin-bottom: 0.4rem; }
    .analysis ul { padding-left: 1.3rem; }

    /* Metric glossary */
    .glossary { background: white; border-radius: 12px; padding: 1.5rem; margin-bottom: 2rem; box-shadow: 0 1px 3px rgba(0,0,0,0.08); }
    .glossary h2 { font-size: 1.15rem; color: #16213e; margin-bottom: 0.8rem; }
    .glossary-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 0.8rem; }
    @media (max-width: 768px) { .glossary-grid { grid-template-columns: 1fr; } }
    .glossary-item { padding: 0.8rem; background: #f9fafb; border-radius: 8px; border-left: 3px solid #3b82f6; }
    .glossary-item h4 { font-size: 0.88rem; color: #16213e; margin-bottom: 0.3rem; }
    .glossary-item .metric-formula { font-family: 'Consolas', 'Monaco', monospace; font-size: 0.8rem; color: #7c3aed; margin-bottom: 0.3rem; }
    .glossary-item p { font-size: 0.82rem; color: #555; line-height: 1.5; }
    .glossary-item.acc { border-left-color: #2563eb; }
    .glossary-item.parse { border-left-color: #0891b2; }
    .glossary-item.faith { border-left-color: #7c3aed; }
    .glossary-item.cons { border-left-color: #16a34a; }
    .glossary-item.steps { border-left-color: #f59e0b; }
    .glossary-item.basic { border-left-color: #6b7280; }

    .footer { text-align: center; color: #94a3b8; font-size: 0.8rem; margin-top: 2rem; padding-top: 1rem; border-top: 1px solid #e5e7eb; }
</style>
</head>
<body>

<a class="back-link" href="index.html">&larr; Back to Hub</a>

<h1>Transfer Evaluation: SARA &amp; LSAT</h1>
<p class="subtitle">Do logic-trained models generalize to real-world legal reasoning and constraint satisfaction?</p>

<div class="key-finding">
    <h2>Key Finding</h2>
    <p>GRPO models trained with SAT consistency rewards on LogicBench show dramatic zero-shot transfer to out-of-domain tasks.
    GRPO Qwen achieves <span class="highlight">24.0% on SARA</span> (vs 2.0% base, 12x improvement) and
    <span class="highlight">11.3% on LSAT</span> (vs 4.8% base, 2.4x improvement) in CoT mode &mdash;
    without any training on legal or constraint satisfaction data.
    GRPO DeepSeek shows even stronger gains: <span class="highlight">40.0% SARA CoT</span> (8x over base) and <span class="highlight">13.0% LSAT CoT</span> (3.3x over base).
    This suggests that learning to reason with verified logical steps transfers broadly.</p>
</div>

<!-- Benchmark Descriptions -->
<div class="benchmarks">
    <div class="benchmark-card">
        <h3>SARA (Statutory Reasoning Assessment)</h3>
        <div class="meta">
            <span class="badge badge-blue">100 test cases</span>
            <span class="badge badge-green">Entailment / Contradiction</span>
            <span class="badge badge-amber">US Tax Code</span>
        </div>
        <p>Reasoning about US tax statutes (IRC Sections 1, 63, 68, 151, 152, 3301, 3306, 7703). Each problem provides statutory facts and a conclusion statement; the model must determine if the conclusion logically follows from the facts (<em>entailment</em>) or contradicts them (<em>contradiction</em>). The prompt asks: &ldquo;Does the following conclusion follow from the facts?&rdquo; Statutes are essentially Horn clauses &mdash; the dataset includes Prolog encodings.</p>
    </div>
    <div class="benchmark-card">
        <h3>LSAT Logic Games (Analytical Reasoning)</h3>
        <div class="meta">
            <span class="badge badge-blue">230 test cases</span>
            <span class="badge badge-green">5-way multiple choice (A&ndash;E)</span>
            <span class="badge badge-amber">Constraint Satisfaction</span>
        </div>
        <p>Constraint satisfaction problems from LSAT Analytical Reasoning sections. Each game presents a scenario with explicit rules about orderings, groupings, or assignments, then asks which configurations are possible or necessary. Requires systematic constraint propagation.</p>
    </div>
</div>

<!-- Metric Glossary -->
<div class="glossary">
    <h2>Metric Definitions</h2>
    <div class="glossary-grid">
        <div class="glossary-item basic">
            <h4>Basic Accuracy</h4>
            <div class="metric-formula">correct / total</div>
            <p>The model is given the problem and asked to answer directly (no chain-of-thought prompting). We extract the final answer from its output and compare to the gold label. This measures raw task performance without structured reasoning.</p>
        </div>
        <div class="glossary-item acc">
            <h4>CoT Accuracy</h4>
            <div class="metric-formula">correct / total</div>
            <p>The model is prompted with a system message instructing it to reason step-by-step using numbered <code>&lt;step&gt;</code> tags (with <code>&lt;text&gt;</code> for natural language and <code>&lt;logic&gt;</code> for formal expressions). We extract the final answer from the end of the chain-of-thought and compare to the gold label. This measures whether structured reasoning improves task accuracy.</p>
        </div>
        <div class="glossary-item parse">
            <h4>Parse Success</h4>
            <div class="metric-formula">parseable_outputs / total</div>
            <p>Fraction of model outputs where at least one valid <code>&lt;step&gt;</code> tag was successfully parsed. A step is parseable if it has the correct XML structure (<code>&lt;step n=... type=...&gt;</code> with <code>&lt;text&gt;</code> and <code>&lt;logic&gt;</code> sub-tags). Low parse success means the model is not following the structured output format at all &mdash; it may be producing free-form text instead.</p>
        </div>
        <div class="glossary-item faith">
            <h4>Faithfulness (F)</h4>
            <div class="metric-formula">all_steps_valid / total</div>
            <p>Fraction of outputs where <strong>every</strong> derived (non-premise) step is logically entailed by the preceding validated steps. A single invalid step makes the whole chain unfaithful. This is the strictest measure: it asks "is the entire reasoning chain logically valid?" Formally: F = 1 iff all derived steps pass SAT entailment check.</p>
        </div>
        <div class="glossary-item cons">
            <h4>Consistency (C)</h4>
            <div class="metric-formula">entailed_derived_steps / total_derived_steps</div>
            <p>Average fraction of derived (non-premise) steps that are logically entailed by prior steps, checked via SAT solver. For each derived step, we test whether the negation of that step is unsatisfiable given the premises and previously validated steps (clean context &mdash; invalid steps do not propagate forward). This is more granular than faithfulness: a chain with 3/4 valid steps gets C = 0.75 but F = 0. <strong>Note:</strong> on SARA/LSAT, C is expected to be low because the SAT solver can only verify propositional logic, not numerical computations or constraint arithmetic.</p>
        </div>
        <div class="glossary-item steps">
            <h4>Avg Steps</h4>
            <div class="metric-formula">mean(steps per output)</div>
            <p>Average number of <code>&lt;step&gt;</code> tags parsed per output. Includes both premise steps (encoding given facts) and derived steps (drawing conclusions). More steps generally indicates more thorough decomposition of the problem. Base models typically produce 0&ndash;1 steps (unstructured), while GRPO models produce 4&ndash;8 steps.</p>
        </div>
    </div>
</div>

<!-- SARA Results Table -->
<div class="table-section">
    <h2>SARA Results</h2>
    <p class="table-note">100 US tax code reasoning problems. Models were trained only on LogicBench (propositional/FOL/non-monotonic logic) &mdash; zero legal training data.</p>
    <table>
        <thead>
            <tr>
                <th>Model</th>
                <th class="num">Basic Acc.</th>
                <th class="num">CoT Acc.</th>
                <th class="num">Parse Success</th>
                <th class="num">Faithfulness</th>
                <th class="num">Consistency</th>
                <th class="num">Avg Steps</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td class="model-base">Base DeepSeek 7B</td>
                <td class="num">2.0%</td>
                <td class="num">5.0%</td>
                <td class="num">33.0%</td>
                <td class="num">9.0%</td>
                <td class="num">0.0%</td>
                <td class="num">0.8</td>
            </tr>
            <tr>
                <td class="model-sft">SFT DeepSeek 7B</td>
                <td class="num">1.0%</td>
                <td class="num">7.0%</td>
                <td class="num">48.0%</td>
                <td class="num">47.0%</td>
                <td class="num">0.0%</td>
                <td class="num">1.1</td>
            </tr>
            <tr>
                <td class="model-grpo">GRPO DeepSeek 7B</td>
                <td class="num">0.0%</td>
                <td class="num best">40.0%</td>
                <td class="num best">97.0%</td>
                <td class="num">24.0%</td>
                <td class="num best">18.3%</td>
                <td class="num">4.5</td>
            </tr>
            <tr><td colspan="7" style="height:4px; background: #f1f5f9; padding:0;"></td></tr>
            <tr>
                <td class="model-base">Base Qwen 8B</td>
                <td class="num">0.0%</td>
                <td class="num">2.0%</td>
                <td class="num">8.0%</td>
                <td class="num">2.0%</td>
                <td class="num">0.0%</td>
                <td class="num">0.2</td>
            </tr>
            <tr>
                <td class="model-sft">SFT Qwen 8B</td>
                <td class="num">0.0%</td>
                <td class="num">4.0%</td>
                <td class="num">59.0%</td>
                <td class="num">58.0%</td>
                <td class="num">0.0%</td>
                <td class="num">1.3</td>
            </tr>
            <tr>
                <td class="model-grpo">GRPO Qwen 8B</td>
                <td class="num">4.0%</td>
                <td class="num">24.0%</td>
                <td class="num best">100%</td>
                <td class="num best">40.0%</td>
                <td class="num">0.3%</td>
                <td class="num">3.7</td>
            </tr>
        </tbody>
    </table>
</div>

<!-- LSAT Results Table -->
<div class="table-section">
    <h2>LSAT Logic Games Results</h2>
    <p class="table-note">230 LSAT Analytical Reasoning questions (5-way multiple choice, 20% random baseline). Same models, zero constraint satisfaction training data.</p>
    <table>
        <thead>
            <tr>
                <th>Model</th>
                <th class="num">Basic Acc.</th>
                <th class="num">CoT Acc.</th>
                <th class="num">Parse Success</th>
                <th class="num">Faithfulness</th>
                <th class="num">Consistency</th>
                <th class="num">Avg Steps</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td class="model-base">Base DeepSeek 7B</td>
                <td class="num">0.0%</td>
                <td class="num">3.9%</td>
                <td class="num">6.5%</td>
                <td class="num">1.7%</td>
                <td class="num">0.0%</td>
                <td class="num">0.2</td>
            </tr>
            <tr>
                <td class="model-sft">SFT DeepSeek 7B</td>
                <td class="num">2.2%</td>
                <td class="num">3.9%</td>
                <td class="num">41.7%</td>
                <td class="num">38.3%</td>
                <td class="num">0.9%</td>
                <td class="num">1.7</td>
            </tr>
            <tr>
                <td class="model-grpo">GRPO DeepSeek 7B</td>
                <td class="num">0.9%</td>
                <td class="num best">13.0%</td>
                <td class="num best">99.6%</td>
                <td class="num">31.3%</td>
                <td class="num best">7.9%</td>
                <td class="num">8.1</td>
            </tr>
            <tr><td colspan="7" style="height:4px; background: #f1f5f9; padding:0;"></td></tr>
            <tr>
                <td class="model-base">Base Qwen 8B</td>
                <td class="num">1.3%</td>
                <td class="num">4.8%</td>
                <td class="num">1.3%</td>
                <td class="num">0.4%</td>
                <td class="num">0.0%</td>
                <td class="num">0.0</td>
            </tr>
            <tr>
                <td class="model-sft">SFT Qwen 8B</td>
                <td class="num">1.3%</td>
                <td class="num">4.8%</td>
                <td class="num">70.9%</td>
                <td class="num">54.3%</td>
                <td class="num">1.1%</td>
                <td class="num">3.5</td>
            </tr>
            <tr>
                <td class="model-grpo">GRPO Qwen 8B</td>
                <td class="num">1.3%</td>
                <td class="num">11.3%</td>
                <td class="num best">99.6%</td>
                <td class="num best">55.7%</td>
                <td class="num">5.6%</td>
                <td class="num">7.2</td>
            </tr>
        </tbody>
    </table>
</div>

<!-- Improvement Summary -->
<div class="table-section">
    <h2>Transfer Improvement Summary</h2>
    <p class="table-note">CoT accuracy improvement from Base to GRPO, showing the effect of logic-focused reinforcement learning on out-of-domain tasks.</p>
    <table>
        <thead>
            <tr>
                <th>Model</th>
                <th>Benchmark</th>
                <th class="num">Base</th>
                <th class="num">SFT</th>
                <th class="num">GRPO</th>
                <th class="num">Improvement (Base&rarr;GRPO)</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>DeepSeek 7B</td>
                <td>SARA CoT</td>
                <td class="num">5.0%</td>
                <td class="num">7.0%</td>
                <td class="num model-grpo">40.0%</td>
                <td class="num"><span class="delta delta-up">+35.0pp (8.0x)</span></td>
            </tr>
            <tr>
                <td>DeepSeek 7B</td>
                <td>LSAT CoT</td>
                <td class="num">3.9%</td>
                <td class="num">3.9%</td>
                <td class="num model-grpo">13.0%</td>
                <td class="num"><span class="delta delta-up">+9.1pp (3.3x)</span></td>
            </tr>
            <tr>
                <td>Qwen 8B</td>
                <td>SARA CoT</td>
                <td class="num">2.0%</td>
                <td class="num">4.0%</td>
                <td class="num model-grpo">24.0%</td>
                <td class="num"><span class="delta delta-up">+22.0pp (12.0x)</span></td>
            </tr>
            <tr>
                <td>Qwen 8B</td>
                <td>LSAT CoT</td>
                <td class="num">4.8%</td>
                <td class="num">4.8%</td>
                <td class="num model-grpo">11.3%</td>
                <td class="num"><span class="delta delta-up">+6.5pp (2.4x)</span></td>
            </tr>
        </tbody>
    </table>
</div>

<!-- Qualitative Examples -->
<div class="examples-section">
    <h2>Qualitative Examples</h2>
    <p class="section-note">Full model outputs on the same problem, comparing Base &rarr; SFT &rarr; GRPO. Scroll within each box to see the complete reasoning trace.</p>

    <!-- SARA Example 1: Qwen 8B -->
    <div class="example-card">
        <h3>SARA: Section 152(a) &mdash; Dependency Determination (Qwen 8B)</h3>
        <div class="example-meta">ID: s152_a_pos &middot; Gold label: Entailment &middot; Section: 152(a)</div>
        <div class="example-prompt">
            <strong>Facts:</strong>
            Alice has a son, Bob, who satisfies section 152(c)(1) for the year 2015.
            <br><br>
            <strong>Conclusion to evaluate:</strong>
            Under section 152(a), Bob is a dependent of Alice for the year 2015.
            <br><br>
            <em style="color:#888; font-size:0.8rem;">Prompt: &ldquo;Does the following conclusion follow from the facts? Answer with: Entailment or Contradiction.&rdquo;</em>
        </div>
        <div class="response-grid">
            <div class="response-box response-wrong">
                <div class="box-header">
                    Base Qwen 8B
                    <span class="verdict verdict-wrong">Predicted: unknown</span>
                </div>
&lt;think&gt;
Okay, let's tackle this problem. The user is asking whether the conclusion that Bob is a dependent of Alice under section 152(a) follows from the given statutory fact that Bob satisfies section 152(c)(1) for 2015.

First, I need to recall what these sections typically mean. Section 152(c)(1) likely relates to the conditions for a qualifying child, which is a part of the dependent rules. If Bob satisfies section 152(c)(1), that probably means he meets the criteria to be a qualifying child, which would make him a dependent under section 152(a).

So the given fact is that Bob satisfies section 152(c)(1). The conclusion is that he's a dependent under section 152(a). The key here is understanding the relationship between these sections. Typically, section 152(c) outlines the requirements for a qualifying child, and section 152(a) defines who is considered a dependent. If someone meets the criteria in section 152(c), they are considered a dependent under section 152(a).

So the lo</div>
            <div class="response-box response-wrong">
                <div class="box-header">
                    SFT Qwen 8B
                    <span class="verdict verdict-wrong">Predicted: unknown</span>
                </div>
&lt;think&gt;
First, I need to understand the statutory provisions referenced. Section 152(c)(1) likely refers to the conditions under which a child is considered a qualifying child for the purposes of the child tax credit or dependency exemption. Section 152(a) likely refers to the general rule that a child is a dependent of a taxpayer.

The fact given: "Alice has a son, Bob, who satisfies section 152(c)(1) for the year 2015." This means Bob meets the requirements of section 152(c)(1). Typically, section 152(c)(1) includes criteria such as relationship, age, residency, and support.

The conclusion: "Under section 152(a), Bob is a dependent of Alice for the year 2015." This is a claim that Bob is a dependent of Alice.

I need to see if satisfying section 152(c)(1) implies that Bob is a dependent under section 152(a). Section 152(a) likely defines what constitutes a dependent. If section 152(c)(1) is a subset of the requirements for being a dependent, then satisfying it would mean Bob is a de</div>
            <div class="response-box response-correct">
                <div class="box-header">
                    GRPO Qwen 8B
                    <span class="verdict verdict-correct">Predicted: Entailment</span>
                </div>
&lt;think&gt;
Let me identify the statutory facts and the rule being applied.

<span class="step-tag">&lt;step n="1" type="premise"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>Alice has a son, Bob, who satisfies section 152(c)(1) for the year 2015. This is given as a fact.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>satisfiesSection152c1(bob, 2015).<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

Section 152(c)(1) likely refers to the definition of a qualifying child under the Internal Revenue Code. If Bob satisfies section 152(c)(1), then he is a qualifying child of Alice, which would make him a dependent under section 152(a).

<span class="step-tag">&lt;step n="2" type="derived" from="1"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>If a child satisfies section 152(c)(1), then they are a qualifying child under section 152(a). Therefore, Bob is a dependent of Alice for the year 2015.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>dependent(alice, bob, 2015) :- satisfiesSection152c1(bob, 2015).<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

<span class="step-tag">&lt;step n="3" type="derived" from="2"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>Since Bob satisfies section 152(c)(1) (Step 1), by Modus Ponens, Bob is a dependent of Alice for the year 2015.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>dependent(alice, bob, 2015).<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

Answer: Entailment</div>
        </div>
    </div>

    <!-- SARA Example 2: DeepSeek 7B -->
    <div class="example-card">
        <h3>SARA: Section 151(d)(3)(A) &mdash; Exemption Reduction Calculation (DeepSeek 7B)</h3>
        <div class="example-meta">ID: s151_d_3_A_pos &middot; Gold label: Entailment &middot; Section: 151(d)(3)(A)</div>
        <div class="example-prompt">
            <strong>Facts:</strong>
            Alice's income in 2015 was $260,932. For 2015, Alice received one exemption of $2,000 under section 151(c). Alice's applicable percentage under section 151(d)(3)(B) is equal to 10%.
            <br><br>
            <strong>Conclusion to evaluate:</strong>
            Under section 151(d)(3)(A), Alice's exemption amount is reduced to $1,800.
            <br><br>
            <em style="color:#888; font-size:0.8rem;">Prompt: &ldquo;Does the following conclusion follow from the facts? Answer with: Entailment or Contradiction.&rdquo;</em>
        </div>
        <div class="response-grid">
            <div class="response-box response-wrong">
                <div class="box-header">
                    Base DeepSeek 7B
                    <span class="verdict verdict-wrong">Predicted: unknown</span>
                </div>
Alright, let's try to figure out if the conclusion about Alice's exemption amount follows from the given facts. So, the facts are that Alice's income in 2015 was $260,932, she received one exemption of $2000 under section 151(c), and her applicable percentage under section 151(d)(3)(B) is 10%. The conclusion claims her exemption is reduced to $1800 under section 151(d)(3)(A).

First, I need to understand the relevant sections. Section 151(c) gives her one exemption of $2000. Then, section 151(d)(3)(B) sets her applicable percentage at 10%. I think the percentage is used to calculate the exemption amount. So, if her percentage is 10%, I should calculate 10% of her income to see if that's the new exemption.

Wait, but she already has one exemption of $2000. Does the 10% apply to that or her income? I'm a bit confused. Maybe the 10% is applied to her income to determine the exemption. So, 10% of $260,932 is $26,093.20. But the conclusion says her exemption is reduced to $1800, which is mu</div>
            <div class="response-box response-wrong">
                <div class="box-header">
                    SFT DeepSeek 7B
                    <span class="verdict verdict-wrong">Predicted: unknown</span>
                </div>
First, I need to identify the facts and the statutory rule being tested.

<span class="step-tag">&lt;step n="1" type="premise"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>Alice's income in 2015 was $260,932. This is given as a fact.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>income(alice, 260932, 2015).<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

<span class="step-tag">&lt;step n="2" type="premise"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>For 2015, Alice received one exemption of $2000 under section 151(c). This is given as a fact.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>exemption(151c, 2000, 2015).<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

<span class="step-tag">&lt;step n="3" type="premise"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>Alice's applicable percentage under section 151(d)(3)(B) is equal to 10%. This is given as a fact.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>applicablePercentage(alice, 10%, 2015).<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

Now, I need to understand the statutory rule. Section 151(d)(3)(A) likely refers to a reduction of the exemption amount. Typically, under section 151(d)(3), the exemption is reduced by a percentage of the income over a certain threshold. The general rule might be: exemption amount = original exemption amount &times; (1 - applicable percentage). But here, the original exemption i</div>
            <div class="response-box response-correct">
                <div class="box-header">
                    GRPO DeepSeek 7B
                    <span class="verdict verdict-correct">Predicted: Entailment</span>
                </div>
First, I need to identify the facts and the statutory rule being tested.

<span class="step-tag">&lt;step n="1" type="premise"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>Alice's income in 2015 was $260,932. This is given as a fact.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>income(alice, 260932, 2015).<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

<span class="step-tag">&lt;step n="2" type="premise"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>For 2015, Alice received one exemption of $2000 under section 151(c). This is given as a fact.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>exemptionAmount(151c, 2000, 2015).<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

<span class="step-tag">&lt;step n="3" type="premise"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>Alice's applicable percentage under section 151(d)(3)(B) is equal to 10%. This is given as a fact.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>applicablePercentage(151d3B, 10, 2015).<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

<span class="step-tag">&lt;step n="4" type="derived" from="2"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>Under section 151(d)(3)(A), the exemption amount is reduced by the applicable percentage. Since the applicable percentage is 10%, the reduction is 10% of the exemption amount.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>exemptionReduction(alice, 10, 2015) :- applicablePercentage(151d3B, 10, 2015) &and; exemptionAmount(151c, 2000, 2015).<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

<span class="step-tag">&lt;step n="5" type="derived" from="2,3,4"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>The reduction amount is $2,000 &times; 10% = $200. The reduced exemption is $2,000 - $200 = $1,800.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>reducedExemption(alice, 1800, 2015).<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

The conclusion states that Alice's exemption amount is reduced to $1,800. This matches the calculated value.

Answer: Entailment</div>
        </div>
    </div>

    <!-- LSAT Example 1: Qwen 8B -->
    <div class="example-card">
        <h3>LSAT: Reading Club &mdash; Valid Selection (Qwen 8B)</h3>
        <div class="example-meta">Gold label: C &middot; 5-way multiple choice (A&ndash;E)</div>
        <div class="example-prompt">
            <strong>Setup:</strong>
            The organizer of a reading club will select at least five and at most six works from a group of nine works. The group consists of three French novels, three Russian novels, two French plays, and one Russian play. The organizer's selection must conform to the following requirements: No more than four French works. At least three but no more than four novels. At least as many French novels as Russian novels. If both French plays are selected, then the Russian play is not selected.
            <br><br>
            <strong>Question:</strong>
            Which one of the following could be the organizer's selection of works?
            (A) one French novel, two Russian novels, one French play, one Russian play
            (B) two French novels, one Russian novel, two French plays, one Russian play
            (C) two French novels, two Russian novels, two French plays
            (D) three French novels, one Russian novel, two French plays
            (E) three French novels, two Russian novels, one French play, one Russian play
        </div>
        <div class="response-grid">
            <div class="response-box response-wrong">
                <div class="box-header">
                    Base Qwen 8B
                    <span class="verdict verdict-wrong">Predicted: unknown</span>
                </div>
&lt;think&gt;
Okay, let's tackle this problem step by step. The question is about selecting works for a reading club with specific constraints. Let me first list out all the constraints to make sure I don't miss any.

First, the organizer needs to select between 5 and 6 works from 9 total. The works are categorized into French novels, Russian novels, French plays, and Russian plays. The constraints are:

1. No more than four French works selected.
2. At least three but no more than four novels selected.
3. At least as many French novels as Russian novels selected.
4. If both French plays are selected, then the Russian play is not selected.

The options are A to E. I need to check each one against these constraints.

Let me start by breaking down each option. Let's go through each step.

First, let's note the categories:

- French novels: 3
- Russian novels: 3
- French plays: 2
- Russian plays: 1

Total works: 3+3+2+1=9.

Now, the constraints:

1. French works (novels + plays) &le;4. So total Fr</div>
            <div class="response-box response-wrong">
                <div class="box-header">
                    SFT Qwen 8B
                    <span class="verdict verdict-wrong">Predicted: unknown</span>
                </div>
&lt;think&gt;
First, I need to formalize the constraints.

Let's define predicates:
- frenchNovel(X): X is a French novel.
- russianNovel(X): X is a Russian novel.
- frenchPlay(X): X is a French play.
- russianPlay(X): X is a Russian play.
- selected(X): X is selected.

We have nine works: three French novels (call them f1, f2, f3), three Russian novels (r1, r2, r3), two French plays (p1, p2), and one Russian play (q1).

Constraints:
1. No more than four French works are selected.
   - French works include French novels and French plays.
   - So: selectedFrenchNovels + selectedFrenchPlays &le; 4.

2. At least three but no more than four novels are selected.
   - Novels include French novels and Russian novels.
   - So: 3 &le; selectedFrenchNovels + selectedRussianNovels &le; 4.

3. At least as many French novels as Russian novels are selected.
   - selectedFrenchNovels &ge; selectedRussianNovels.

4. If both French plays are selected, then the Russian play is not selected.
   - If selectedFrenchPlays = </div>
            <div class="response-box response-correct">
                <div class="box-header">
                    GRPO Qwen 8B
                    <span class="verdict verdict-correct">Predicted: C</span>
                </div>
&lt;think&gt;
Let me first formalize the constraints.

<span class="step-tag">&lt;step n="1" type="premise"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>Total works selected: at least 5 and at most 6.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>5 &le; total &le; 6.<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

<span class="step-tag">&lt;step n="2" type="premise"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>Group composition: 3 French novels (F_n), 3 Russian novels (R_n), 2 French plays (F_p), 1 Russian play (R_p).<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>totalWorks = 3 + 3 + 2 + 1 = 9.<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

<span class="step-tag">&lt;step n="3" type="premise"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>No more than four French works are selected.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>~(F_n + F_p &gt; 4).<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

<span class="step-tag">&lt;step n="4" type="premise"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>At least three but no more than four novels are selected.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>3 &le; (F_n + R_n) &le; 4.<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

<span class="step-tag">&lt;step n="5" type="premise"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>At least as many French novels as Russian novels are selected.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>F_n &ge; R_n.<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

<span class="step-tag">&lt;step n="6" type="premise"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>If both French plays are selected, then the Russian play is not selected.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>~R_p :- F_p = 2.<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

Now I'll test each option against these constraints.

Option (A): 1F_n + 2R_n + 1F_p + 1R_p = 5 works. Total OK.
French: 1 + 1 = 2 &le; 4. OK.
Novels: 1 + 2 = 3. 3 &le; 3 &le; 4. OK.
F_n &ge; R_n: 1 &ge; 2? NO. Fails constraint 5.

Option (B): 2F_n + 1R_n + 2F_p + 1R_p = 6 works. Total OK.
French: 2 + 2 = 4 &le; 4. OK.
Novels: 2 + 1 = 3. OK.
F_n &ge; R_n: 2 &ge; 1. OK.
Both French plays selected AND Russian play selected? Fails constraint 6.

Option (C): 2F_n + 2R_n + 2F_p = 6 works. Total OK.
French: 2 + 2 = 4 &le; 4. OK.
Novels: 2 + 2 = 4. 3 &le; 4 &le; 4. OK.
F_n &ge; R_n: 2 &ge; 2. OK.
Both French plays selected, no Russian play. OK.
All constraints satisfied.

Answer: C</div>
        </div>
    </div>

    <!-- LSAT Example 2: DeepSeek 7B -->
    <div class="example-card">
        <h3>LSAT: Reading Club &mdash; Minimum Selection Requirement (DeepSeek 7B)</h3>
        <div class="example-meta">Gold label: D &middot; 5-way multiple choice (A&ndash;E)</div>
        <div class="example-prompt">
            <strong>Setup:</strong>
            (Same reading club scenario as above)
            <br><br>
            <strong>Question:</strong>
            The organizer must at least select
            (A) one French novel and one French play
            (B) one French novel and one Russian play
            (C) one Russian novel and one French play
            (D) two French novels
            (E) two Russian novels
        </div>
        <div class="response-grid">
            <div class="response-box response-wrong">
                <div class="box-header">
                    Base DeepSeek 7B
                    <span class="verdict verdict-wrong">Predicted: unknown</span>
                </div>
Alright, let's tackle this problem step by step. So, the organizer is selecting works from a group of nine, which includes different categories: French novels, Russian novels, French plays, and a Russian play. The constraints are a bit complex, so I need to break them down one by one.

First, the organizer must select at least five and at most six works. That means the total number of works selected, N, must satisfy 5 &le; N &le; 66. So, N can be 5, 66, or 6.

Next, the group composition: there are 3 French novels, 3 Russian novels, 2 French plays, and 1 Russian play. So, total works are 3+3+2+1=9, which matches the initial statement.

Now, the constraints:

1. No more than four French works are selected. So, the total number of French works (French novels + French plays) cannot exceed 4. Since there are only 2 French plays, the maximum French works possible are 4 (if both plays are selected along with 2 novels). But wait, the organizer can't select more than 4 French works, so French novels</div>
            <div class="response-box response-wrong">
                <div class="box-header">
                    SFT DeepSeek 7B
                    <span class="verdict verdict-wrong">Predicted: unknown</span>
                </div>
First, I need to parse the problem and identify the constraints.

We have a group of nine works:
- 3 French novels
- 3 Russian novels
- 2 French plays
- 1 Russian play.

The organizer selects at least five and at most six works. So the total selected is 5 or 6.

Constraints:
1. No more than four French works are selected. Since there are only 3 French novels and 2 French plays, total French works possible: 3 + 2 = 5. So "no more than four" means at most 4 French works selected. That is, French novels + French plays &le; 4.

2. At least three but no more than four novels are selected. Novels are both French and Russian. So total novels selected &ge;3 and &le;4.

3. At least as many French novels as Russian novels are selected. So French novels selected &ge; Russian novels selected.

4. If both French plays are selected, then the Russian play is not selected.

We need to determine what must be selected: the organizer must at least select one of the options (A) to (E). That is, we need to find which </div>
            <div class="response-box response-correct">
                <div class="box-header">
                    GRPO DeepSeek 7B
                    <span class="verdict verdict-correct">Predicted: D</span>
                </div>
First, let's formalize the constraints.

<span class="step-tag">&lt;step n="1" type="premise"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>Constraint 1: At least five and at most six works are selected.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>5 &le; totalSelection &le; 6.<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

<span class="step-tag">&lt;step n="2" type="premise"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>Constraint 2: No more than four French works are selected.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>max(french, 4).<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

<span class="step-tag">&lt;step n="3" type="premise"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>Constraint 3: At least three but no more than four novels are selected.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>3 &le; novels &le; 4.<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

<span class="step-tag">&lt;step n="4" type="premise"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>Constraint 4: At least as many French novels as Russian novels are selected.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>frenchNovels &ge; russianNovels.<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

<span class="step-tag">&lt;step n="5" type="premise"&gt;</span>
<span class="logic-tag">&lt;text&gt;</span>Constraint 5: If both French plays are selected, then the Russian play is not selected.<span class="logic-tag">&lt;/text&gt;</span>
<span class="logic-tag">&lt;logic&gt;</span>(frenchPlays &ge; 2) &rarr; ~russianPlay.<span class="logic-tag">&lt;/logic&gt;</span>
<span class="step-tag">&lt;/step&gt;</span>

Now, let's analyze the options.

Option (A): one French novel and one French play.
- French novel: 1
- French play: 1
- Total French: 2
- Novels: 1 (French) + ? (Russian) &ge; 3, so we need at least 2 Russian novels.
- But frenchNovels &ge; russianNovels: 1 &ge; 2? NO. Cannot guarantee this constraint.
- So (A) is not necessarily selected.

Option (D): two French novels.
- With novels &ge; 3 and frenchNovels &ge; russianNovels, if frenchNovels = 2, then russianNovels &le; 2.
- novels = frenchNovels + russianNovels &ge; 3, so russianNovels &ge; 1.
- If frenchNovels = 1, then russianNovels &le; 1, so novels &le; 2 &lt; 3. Fails constraint 3.
- Therefore frenchNovels &ge; 2 is required in all valid selections.

Answer: D</div>
        </div>
    </div>
</div>

<!-- Analysis -->
<div class="analysis">
    <h2>Analysis</h2>

    <h3>Why does GRPO transfer to legal and constraint reasoning?</h3>
    <p>GRPO models trained with SAT consistency rewards learn three transferable skills:</p>
    <ul>
        <li><strong>Structured decomposition:</strong> Breaking problems into numbered, typed premises and derived steps. This format transfers naturally to statutory reasoning (each statute clause becomes a premise) and constraint satisfaction (each rule becomes a premise).</li>
        <li><strong>Formal representation:</strong> Encoding natural language as logical expressions (Prolog-style predicates, inequality constraints). Even when the specific formalism differs from training, the habit of formalization improves accuracy.</li>
        <li><strong>Step-by-step derivation:</strong> Explicitly citing which prior steps support each conclusion. This prevents the "reasoning by vibes" failure mode common in base models.</li>
    </ul>

    <h3>Key observations</h3>
    <ul>
        <li><strong>SFT alone is insufficient:</strong> SFT teaches the output format (&lt;step&gt; tags) but doesn't improve accuracy on transfer tasks. The model learns to generate structured-looking text without learning to reason structurally. GRPO's consistency reward is the critical ingredient.</li>
        <li><strong>Parse success correlates with accuracy:</strong> GRPO models achieve near-100% parse success (well-formed &lt;step&gt; tags), while base models rarely produce parseable structured reasoning. This structural discipline appears to force more careful thinking.</li>
        <li><strong>Basic mode fails uniformly:</strong> All models perform near-zero in basic (no-CoT) mode. These tasks genuinely require multi-step reasoning; the model cannot shortcut to the answer.</li>
        <li><strong>Consistency is domain-limited:</strong> SAT consistency rates are low (0&ndash;18%) because the SAT verifier cannot evaluate numerical computations (tax calculations) or constraint satisfaction logic. This is expected and motivates domain-specific verifiers (Paper 2).</li>
        <li><strong>DeepSeek vs Qwen:</strong> DeepSeek 7B shows stronger GRPO transfer than Qwen 8B, possibly because DeepSeek-R1-Distill already has reasoning capabilities that GRPO further sharpens.</li>
    </ul>

    <h3>Limitations</h3>
    <ul>
        <li>Absolute accuracy remains low (&lt;40% SARA, &lt;13% LSAT). These benchmarks are hard for small models. The main finding is <em>relative improvement</em> from logic training.</li>
        <li>LSAT random baseline is 20%. GRPO models at 11&ndash;13% are below random chance in absolute terms, but the improvement over base (3.9&ndash;4.8%) is real and consistent.</li>
        <li>No domain-specific few-shot examples were used during evaluation, which may disadvantage all models equally.</li>
    </ul>
</div>

<div class="footer">
    Updated February 21, 2026 &middot;
    RAILS (Reasoning with Automatically Integrated Logical Supervision) &middot;
    ProofContinuity
</div>

</body>
</html>
