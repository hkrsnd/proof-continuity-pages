<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>RAILS â€” Transfer Evaluation: SARA &amp; LSAT</title>
<style>
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body { font-family: 'Segoe UI', system-ui, -apple-system, sans-serif; background: #f8f9fa; color: #1a1a2e; line-height: 1.6; padding: 2rem; max-width: 1100px; margin: 0 auto; }
    a { color: #2563eb; text-decoration: none; }
    a:hover { text-decoration: underline; }
    h1 { font-size: 1.8rem; margin-bottom: 0.3rem; color: #16213e; }
    .subtitle { color: #666; font-size: 0.95rem; margin-bottom: 1.5rem; }
    .back-link { display: inline-block; margin-bottom: 1.5rem; font-size: 0.9rem; }

    /* Summary cards */
    .key-finding { background: linear-gradient(135deg, #eff6ff, #f0f4ff); border-radius: 12px; padding: 1.5rem; margin-bottom: 2rem; border-left: 4px solid #2563eb; }
    .key-finding h2 { font-size: 1.1rem; color: #16213e; margin-bottom: 0.6rem; }
    .key-finding p { font-size: 0.9rem; color: #444; }
    .key-finding .highlight { font-weight: 700; color: #2563eb; }

    /* Benchmark description */
    .benchmarks { display: grid; grid-template-columns: 1fr 1fr; gap: 1.2rem; margin-bottom: 2rem; }
    .benchmark-card { background: white; border-radius: 12px; padding: 1.3rem; box-shadow: 0 1px 3px rgba(0,0,0,0.08); }
    .benchmark-card h3 { font-size: 1rem; color: #16213e; margin-bottom: 0.4rem; }
    .benchmark-card .meta { font-size: 0.8rem; color: #888; margin-bottom: 0.5rem; }
    .benchmark-card p { font-size: 0.85rem; color: #555; }
    .benchmark-card .badge { display: inline-block; padding: 0.15rem 0.5rem; border-radius: 20px; font-size: 0.72rem; font-weight: 600; margin-right: 0.3rem; }
    .badge-blue { background: #e0e7ff; color: #3730a3; }
    .badge-green { background: #dcfce7; color: #166534; }
    .badge-amber { background: #fef3c7; color: #92400e; }

    /* Tables */
    .table-section { background: white; border-radius: 12px; padding: 1.5rem; margin-bottom: 2rem; box-shadow: 0 1px 3px rgba(0,0,0,0.08); }
    .table-section h2 { font-size: 1.15rem; color: #16213e; margin-bottom: 0.3rem; }
    .table-section .table-note { font-size: 0.82rem; color: #888; margin-bottom: 1rem; }
    table { width: 100%; border-collapse: collapse; font-size: 0.85rem; }
    th { background: #f1f5f9; padding: 0.6rem 0.8rem; text-align: left; font-weight: 600; color: #475569; border-bottom: 2px solid #e2e8f0; }
    td { padding: 0.55rem 0.8rem; border-bottom: 1px solid #f1f5f9; }
    tr:hover td { background: #f8fafc; }
    .num { text-align: right; font-variant-numeric: tabular-nums; }
    .best { font-weight: 700; color: #16a34a; }
    .model-base { color: #6b7280; }
    .model-sft { color: #7c3aed; }
    .model-grpo { color: #2563eb; font-weight: 600; }
    .delta { font-size: 0.75rem; font-weight: 600; }
    .delta-up { color: #16a34a; }
    .delta-down { color: #dc2626; }

    /* Qualitative examples */
    .examples-section { margin-bottom: 2rem; }
    .examples-section h2 { font-size: 1.15rem; color: #16213e; margin-bottom: 0.5rem; }
    .examples-section .section-note { font-size: 0.82rem; color: #888; margin-bottom: 1rem; }

    .example-card { background: white; border-radius: 12px; padding: 1.5rem; margin-bottom: 1.5rem; box-shadow: 0 1px 3px rgba(0,0,0,0.08); }
    .example-card h3 { font-size: 1rem; color: #16213e; margin-bottom: 0.5rem; }
    .example-meta { font-size: 0.8rem; color: #888; margin-bottom: 0.8rem; }
    .example-prompt { background: #f8f9fa; border-radius: 8px; padding: 1rem; margin-bottom: 1rem; font-size: 0.85rem; color: #333; border-left: 3px solid #94a3b8; }
    .example-prompt strong { color: #16213e; display: block; margin-bottom: 0.3rem; font-size: 0.8rem; }

    .response-grid { display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 1rem; }
    @media (max-width: 1000px) {
        .response-grid { grid-template-columns: 1fr; }
        .benchmarks { grid-template-columns: 1fr; }
    }

    .response-box { border-radius: 8px; padding: 1rem; font-size: 0.82rem; font-family: 'Consolas', 'Monaco', monospace; white-space: pre-wrap; word-break: break-word; overflow: auto; max-height: 400px; }
    .response-box .box-header { font-family: 'Segoe UI', sans-serif; font-weight: 700; font-size: 0.85rem; margin-bottom: 0.5rem; display: flex; justify-content: space-between; align-items: center; }
    .response-correct { background: #f0fdf4; border: 1px solid #bbf7d0; }
    .response-correct .box-header { color: #166534; }
    .response-wrong { background: #fef2f2; border: 1px solid #fecaca; }
    .response-wrong .box-header { color: #991b1b; }
    .response-neutral { background: #f8f9fa; border: 1px solid #e5e7eb; }
    .response-neutral .box-header { color: #374151; }
    .verdict { font-size: 0.75rem; font-weight: 600; padding: 0.1rem 0.4rem; border-radius: 10px; }
    .verdict-correct { background: #dcfce7; color: #166534; }
    .verdict-wrong { background: #fecaca; color: #991b1b; }

    .step-tag { color: #7c3aed; font-weight: 600; }
    .logic-tag { color: #0369a1; }
    .truncated { color: #9ca3af; font-style: italic; font-family: 'Segoe UI', sans-serif; }

    /* Analysis section */
    .analysis { background: white; border-radius: 12px; padding: 1.5rem; margin-bottom: 2rem; box-shadow: 0 1px 3px rgba(0,0,0,0.08); }
    .analysis h2 { font-size: 1.15rem; color: #16213e; margin-bottom: 0.8rem; }
    .analysis h3 { font-size: 0.95rem; color: #475569; margin-top: 1rem; margin-bottom: 0.4rem; }
    .analysis p, .analysis li { font-size: 0.88rem; color: #555; margin-bottom: 0.4rem; }
    .analysis ul { padding-left: 1.3rem; }

    /* Metric glossary */
    .glossary { background: white; border-radius: 12px; padding: 1.5rem; margin-bottom: 2rem; box-shadow: 0 1px 3px rgba(0,0,0,0.08); }
    .glossary h2 { font-size: 1.15rem; color: #16213e; margin-bottom: 0.8rem; }
    .glossary-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 0.8rem; }
    @media (max-width: 768px) { .glossary-grid { grid-template-columns: 1fr; } }
    .glossary-item { padding: 0.8rem; background: #f9fafb; border-radius: 8px; border-left: 3px solid #3b82f6; }
    .glossary-item h4 { font-size: 0.88rem; color: #16213e; margin-bottom: 0.3rem; }
    .glossary-item .metric-formula { font-family: 'Consolas', 'Monaco', monospace; font-size: 0.8rem; color: #7c3aed; margin-bottom: 0.3rem; }
    .glossary-item p { font-size: 0.82rem; color: #555; line-height: 1.5; }
    .glossary-item.acc { border-left-color: #2563eb; }
    .glossary-item.parse { border-left-color: #0891b2; }
    .glossary-item.faith { border-left-color: #7c3aed; }
    .glossary-item.cons { border-left-color: #16a34a; }
    .glossary-item.steps { border-left-color: #f59e0b; }
    .glossary-item.basic { border-left-color: #6b7280; }

    .footer { text-align: center; color: #94a3b8; font-size: 0.8rem; margin-top: 2rem; padding-top: 1rem; border-top: 1px solid #e5e7eb; }
</style>
</head>
<body>

<a class="back-link" href="index.html">&larr; Back to Hub</a>

<h1>Transfer Evaluation: SARA &amp; LSAT</h1>
<p class="subtitle">Do logic-trained models generalize to real-world legal reasoning and constraint satisfaction?</p>

<div class="key-finding">
    <h2>Key Finding</h2>
    <p>GRPO models trained with SAT consistency rewards on LogicBench show consistent zero-shot transfer to out-of-domain tasks.
    GRPO Qwen achieves <span class="highlight">43.0% on SARA</span> (vs 16.0% base, +27pp) and
    <span class="highlight">28.3% on LSAT</span> (vs 21.7% base, +6.6pp) in CoT mode &mdash;
    without any training on legal or constraint satisfaction data.
    GRPO DeepSeek achieves <span class="highlight">40.0% SARA CoT</span> (vs 35.0% base) and <span class="highlight">17.0% LSAT CoT</span> (vs 15.2% base).
    Crucially, SFT alone <em>hurts</em> transfer performance (dropping below base), while GRPO recovers and surpasses it &mdash;
    suggesting that the consistency reward teaches genuinely transferable reasoning skills, not just output formatting.</p>
</div>

<!-- Benchmark Descriptions -->
<div class="benchmarks">
    <div class="benchmark-card">
        <h3>SARA (Statutory Reasoning Assessment)</h3>
        <div class="meta">
            <span class="badge badge-blue">100 test cases</span>
            <span class="badge badge-green">Entailment / Contradiction</span>
            <span class="badge badge-amber">US Tax Code</span>
        </div>
        <p>Reasoning about US tax statutes (IRC Sections 1, 63, 68, 151, 152, 3301, 3306, 7703). Each problem provides statutory facts and a conclusion statement; the model must determine if the conclusion logically follows from the facts (<em>entailment</em>) or contradicts them (<em>contradiction</em>). The prompt asks: &ldquo;Does the following conclusion follow from the facts?&rdquo; Statutes are essentially Horn clauses &mdash; the dataset includes Prolog encodings.</p>
    </div>
    <div class="benchmark-card">
        <h3>LSAT Logic Games (Analytical Reasoning)</h3>
        <div class="meta">
            <span class="badge badge-blue">230 test cases</span>
            <span class="badge badge-green">5-way multiple choice (A&ndash;E)</span>
            <span class="badge badge-amber">Constraint Satisfaction</span>
        </div>
        <p>Constraint satisfaction problems from LSAT Analytical Reasoning sections. Each game presents a scenario with explicit rules about orderings, groupings, or assignments, then asks which configurations are possible or necessary. Requires systematic constraint propagation.</p>
    </div>
</div>

<!-- Metric Glossary -->
<div class="glossary">
    <h2>Metric Definitions</h2>
    <div class="glossary-grid">
        <div class="glossary-item basic">
            <h4>Basic Accuracy</h4>
            <div class="metric-formula">correct / total</div>
            <p>The model is given the problem and asked to answer directly (no chain-of-thought prompting). We extract the final answer from its output and compare to the gold label. This measures raw task performance without structured reasoning.</p>
        </div>
        <div class="glossary-item acc">
            <h4>CoT Accuracy</h4>
            <div class="metric-formula">correct / total</div>
            <p>The model is prompted with a system message instructing it to reason step-by-step using numbered <code>&lt;step&gt;</code> tags (with <code>&lt;text&gt;</code> for natural language and <code>&lt;logic&gt;</code> for formal expressions). We extract the final answer from the end of the chain-of-thought and compare to the gold label. This measures whether structured reasoning improves task accuracy.</p>
        </div>
        <div class="glossary-item parse">
            <h4>Parse Success</h4>
            <div class="metric-formula">parseable_outputs / total</div>
            <p>Fraction of model outputs where at least one valid <code>&lt;step&gt;</code> tag was successfully parsed. A step is parseable if it has the correct XML structure (<code>&lt;step n=... type=...&gt;</code> with <code>&lt;text&gt;</code> and <code>&lt;logic&gt;</code> sub-tags). Low parse success means the model is not following the structured output format at all &mdash; it may be producing free-form text instead.</p>
        </div>
        <div class="glossary-item faith">
            <h4>Faithfulness (F)</h4>
            <div class="metric-formula">all_steps_valid / total</div>
            <p>Fraction of outputs where <strong>every</strong> derived (non-premise) step is logically entailed by the preceding validated steps. A single invalid step makes the whole chain unfaithful. This is the strictest measure: it asks "is the entire reasoning chain logically valid?" Formally: F = 1 iff all derived steps pass SAT entailment check.</p>
        </div>
        <div class="glossary-item cons">
            <h4>Consistency (C)</h4>
            <div class="metric-formula">entailed_derived_steps / total_derived_steps</div>
            <p>Average fraction of derived (non-premise) steps that are logically entailed by prior steps, checked via SAT solver. For each derived step, we test whether the negation of that step is unsatisfiable given the premises and previously validated steps (clean context &mdash; invalid steps do not propagate forward). This is more granular than faithfulness: a chain with 3/4 valid steps gets C = 0.75 but F = 0. <strong>Note:</strong> on SARA/LSAT, C is expected to be near zero because the SAT solver can only verify propositional logic, not numerical computations or constraint arithmetic.</p>
        </div>
        <div class="glossary-item steps">
            <h4>Avg Steps</h4>
            <div class="metric-formula">mean(steps per output)</div>
            <p>Average number of <code>&lt;step&gt;</code> tags parsed per output. Includes both premise steps (encoding given facts) and derived steps (drawing conclusions). More steps generally indicates more thorough decomposition of the problem.</p>
        </div>
    </div>
</div>

<!-- SARA Results Table -->
<div class="table-section">
    <h2>SARA Results</h2>
    <p class="table-note">100 US tax code reasoning problems. Models were trained only on LogicBench (propositional/FOL/non-monotonic logic) &mdash; zero legal training data. CoT max tokens: 1024.</p>
    <table>
        <thead>
            <tr>
                <th>Model</th>
                <th class="num">Basic Acc.</th>
                <th class="num">CoT Acc.</th>
                <th class="num">Parse Success</th>
                <th class="num">Faithfulness</th>
                <th class="num">Consistency</th>
                <th class="num">Avg Steps</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td class="model-base">Base DeepSeek 7B</td>
                <td class="num">2.0%</td>
                <td class="num">35.0%</td>
                <td class="num best">84.0%</td>
                <td class="num best">11.0%</td>
                <td class="num best">0.3%</td>
                <td class="num">3.4</td>
            </tr>
            <tr>
                <td class="model-sft">SFT DeepSeek 7B</td>
                <td class="num">1.0%</td>
                <td class="num">5.0%</td>
                <td class="num">3.0%</td>
                <td class="num">3.0%</td>
                <td class="num">0.0%</td>
                <td class="num">0.1</td>
            </tr>
            <tr>
                <td class="model-grpo">GRPO DeepSeek 7B</td>
                <td class="num">0.0%</td>
                <td class="num best">40.0%</td>
                <td class="num">6.0%</td>
                <td class="num">1.0%</td>
                <td class="num">0.0%</td>
                <td class="num">0.2</td>
            </tr>
            <tr><td colspan="7" style="height:4px; background: #f1f5f9; padding:0;"></td></tr>
            <tr>
                <td class="model-base">Base Qwen 8B</td>
                <td class="num">0.0%</td>
                <td class="num">16.0%</td>
                <td class="num">49.0%</td>
                <td class="num">10.0%</td>
                <td class="num">0.0%</td>
                <td class="num">1.5</td>
            </tr>
            <tr>
                <td class="model-sft">SFT Qwen 8B</td>
                <td class="num">0.0%</td>
                <td class="num">11.0%</td>
                <td class="num">14.0%</td>
                <td class="num">6.0%</td>
                <td class="num">0.0%</td>
                <td class="num">0.4</td>
            </tr>
            <tr>
                <td class="model-grpo">GRPO Qwen 8B</td>
                <td class="num">4.0%</td>
                <td class="num best">43.0%</td>
                <td class="num best">55.0%</td>
                <td class="num best">19.0%</td>
                <td class="num">0.0%</td>
                <td class="num">2.2</td>
            </tr>
        </tbody>
    </table>
</div>

<!-- LSAT Results Table -->
<div class="table-section">
    <h2>LSAT Logic Games Results</h2>
    <p class="table-note">230 LSAT Analytical Reasoning questions (5-way multiple choice, 20% random baseline). Same models, zero constraint satisfaction training data. CoT max tokens: 2048.</p>
    <table>
        <thead>
            <tr>
                <th>Model</th>
                <th class="num">Basic Acc.</th>
                <th class="num">CoT Acc.</th>
                <th class="num">Parse Success</th>
                <th class="num">Faithfulness</th>
                <th class="num">Consistency</th>
                <th class="num">Avg Steps</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td class="model-base">Base DeepSeek 7B</td>
                <td class="num">0.0%</td>
                <td class="num">15.2%</td>
                <td class="num best">23.0%</td>
                <td class="num best">3.5%</td>
                <td class="num">0.0%</td>
                <td class="num">1.0</td>
            </tr>
            <tr>
                <td class="model-sft">SFT DeepSeek 7B</td>
                <td class="num">2.2%</td>
                <td class="num">9.1%</td>
                <td class="num">4.8%</td>
                <td class="num">0.0%</td>
                <td class="num">0.0%</td>
                <td class="num">0.2</td>
            </tr>
            <tr>
                <td class="model-grpo">GRPO DeepSeek 7B</td>
                <td class="num">0.9%</td>
                <td class="num best">17.0%</td>
                <td class="num">6.5%</td>
                <td class="num">1.3%</td>
                <td class="num">0.0%</td>
                <td class="num">0.2</td>
            </tr>
            <tr><td colspan="7" style="height:4px; background: #f1f5f9; padding:0;"></td></tr>
            <tr>
                <td class="model-base">Base Qwen 8B</td>
                <td class="num">1.3%</td>
                <td class="num">21.7%</td>
                <td class="num">17.0%</td>
                <td class="num">0.9%</td>
                <td class="num">0.0%</td>
                <td class="num">0.9</td>
            </tr>
            <tr>
                <td class="model-sft">SFT Qwen 8B</td>
                <td class="num">1.3%</td>
                <td class="num">16.1%</td>
                <td class="num">14.8%</td>
                <td class="num">1.3%</td>
                <td class="num">0.2%</td>
                <td class="num">1.0</td>
            </tr>
            <tr>
                <td class="model-grpo">GRPO Qwen 8B</td>
                <td class="num">1.3%</td>
                <td class="num best">28.3%</td>
                <td class="num best">18.7%</td>
                <td class="num best">0.9%</td>
                <td class="num best">0.3%</td>
                <td class="num">2.0</td>
            </tr>
        </tbody>
    </table>
</div>

<!-- Improvement Summary -->
<div class="table-section">
    <h2>Transfer Improvement Summary</h2>
    <p class="table-note">CoT accuracy from Base &rarr; SFT &rarr; GRPO, showing the effect of logic-focused training on out-of-domain tasks.</p>
    <table>
        <thead>
            <tr>
                <th>Model</th>
                <th>Benchmark</th>
                <th class="num">Base</th>
                <th class="num">SFT</th>
                <th class="num">GRPO</th>
                <th class="num">Base&rarr;GRPO</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>DeepSeek 7B</td>
                <td>SARA CoT</td>
                <td class="num">35.0%</td>
                <td class="num"><span class="delta delta-down">5.0%</span></td>
                <td class="num model-grpo">40.0%</td>
                <td class="num"><span class="delta delta-up">+5.0pp (1.1x)</span></td>
            </tr>
            <tr>
                <td>DeepSeek 7B</td>
                <td>LSAT CoT</td>
                <td class="num">15.2%</td>
                <td class="num"><span class="delta delta-down">9.1%</span></td>
                <td class="num model-grpo">17.0%</td>
                <td class="num"><span class="delta delta-up">+1.8pp (1.1x)</span></td>
            </tr>
            <tr>
                <td>Qwen 8B</td>
                <td>SARA CoT</td>
                <td class="num">16.0%</td>
                <td class="num"><span class="delta delta-down">11.0%</span></td>
                <td class="num model-grpo">43.0%</td>
                <td class="num"><span class="delta delta-up">+27.0pp (2.7x)</span></td>
            </tr>
            <tr>
                <td>Qwen 8B</td>
                <td>LSAT CoT</td>
                <td class="num">21.7%</td>
                <td class="num"><span class="delta delta-down">16.1%</span></td>
                <td class="num model-grpo">28.3%</td>
                <td class="num"><span class="delta delta-up">+6.6pp (1.3x)</span></td>
            </tr>
        </tbody>
    </table>
</div>

<!-- Qualitative Examples -->
<div class="examples-section">
    <h2>Qualitative Examples</h2>
    <p class="section-note">Model outputs on the same problem, comparing Base &rarr; SFT &rarr; GRPO. Outputs are shown up to 1000 characters; full generation continues beyond. Scroll within each box to see the complete excerpt.</p>

    <!-- SARA Example 1: Qwen 8B -->
    <div class="example-card">
        <h3>SARA: Section 152(d)(1)(D) &mdash; Dependency Determination (Qwen 8B)</h3>
        <div class="example-meta">ID: s152_d_1_D_neg &middot; Gold label: Contradiction &middot; Section: 152(d)(1)(D)</div>
        <div class="example-prompt">
            <strong>Facts:</strong>
            In 2015, Alice's income was $312. The exemption amount for Alice under section 151(d) for the year 2015 was $2000. Alice is Bob's mother, and Bob is a dependent of Alice under 152(c) for the year 2015.
            <br><br>
            <strong>Conclusion to evaluate:</strong>
            Section 152(d)(1)(D) applies to Bob for the year 2015.
            <br><br>
            <em style="color:#888; font-size:0.8rem;">Prompt: &ldquo;Does the following conclusion follow from the facts? Answer with: Entailment or Contradiction.&rdquo;</em>
        </div>
        <div class="response-grid">
            <div class="response-box response-wrong">
                <div class="box-header">
                    Base Qwen 8B
                    <span class="verdict verdict-wrong">Predicted: unknown</span>
                </div>
&lt;think&gt;
Okay, let's tackle this problem step by step. The user is asking whether the conclusion that Section 152(d)(1)(D) applies to Bob for 2015 follows from the given statutory facts.

First, I need to parse the given facts. The facts are:

1. In 2015, Alice's income was $312.
2. The exemption amount for Alice under section 151(d) for 2015 was $2000.
3. Alice is Bob's mother, and Bob is a dependent of Alice under 152(c) for 2015.

The conclusion is that Section 152(d)(1)(D) applies to Bob for 2015.

I need to check if these facts logically lead to the conclusion. Let's break down each part.

Starting with the first fact: Alice's income in 2015 was $312. This is a fact about her income, which might be relevant for determining exemptions or dependents.

Second fact: The exemption amount for Alice under section 151(d) was $2000. Section 151(d) likely refers to the personal exemption amount. So Alice's personal exemption is $2000.

Third fact: Alice is Bob's mother, and Bob is a depen<span class="truncated">[...continues]</span></div>
            <div class="response-box response-wrong">
                <div class="box-header">
                    SFT Qwen 8B
                    <span class="verdict verdict-wrong">Predicted: unknown</span>
                </div>
&lt;think&gt;
First, I need to parse the given statutory facts and the conclusion. The facts are:

1. In 2015, Alice's income was $312.
2. The exemption amount for Alice under section 151(d) for the year 2015 was $2000.
3. Alice is Bob's mother, and Bob is a dependent of Alice under 152(c) for the year 2015.

The conclusion is: "Section 152(d)(1)(D) applies to Bob for the year 2015."

I need to determine if this conclusion logically follows from the given facts using valid inference rules.

Let's break down the facts into logical statements.

Fact 1: Alice's income in 2015 was $312.
Fact 2: Exemption amount for Alice under section 151(d) in 2015 was $2000.
Fact 3: Alice is Bob's mother, and Bob is a dependent of Alice under 152(c) for 2015.

I need to see if there is a rule that connects these facts to the conclusion that section 152(d)(1)(D) applies to Bob.

First, I'll formalize the facts.

Step 1:
(Text) Alice's income in 2015 was $312. This is given as a fact.
(Logic) income(alice, 312, <span class="truncated">[...continues]</span></div>
            <div class="response-box response-correct">
                <div class="box-header">
                    GRPO Qwen 8B
                    <span class="verdict verdict-correct">Predicted: contradiction</span>
                </div>
&lt;think&gt;
Let's analyze the given statutory facts and see if the conclusion follows.

First, we have Alice's income and exemption amount.
Then, we have that Alice is Bob's mother, and Bob is a dependent of Alice under section 152(c) for 2015.

The conclusion is that section 152(d)(1)(D) applies to Bob for 2015.

We need to see if the facts imply that section 152(d)(1)(D) applies to Bob.

Section 152(c) likely deals with the definition of a dependent, while section 152(d)(1)(D) might be about the dependency exemption or other rules.

But the given facts only mention that Bob is a dependent under section 152(c). There's no direct statement that section 152(d)(1)(D) applies to Bob.

Therefore, the conclusion does not necessarily follow from the given facts.

Let's formalize the steps.

Step 1:
(Text) Alice's income in 2015 was $312. This is given as a fact.
(Logic) income(alice, 312, 2015).

Step 2:
(Text) The exemption amount for Alice under section 151(d) for 2015 was $2000. This is given<span class="truncated">[...continues &rarr; concludes: Contradiction]</span></div>
        </div>
    </div>

    <!-- SARA Example 2: DeepSeek 7B -->
    <div class="example-card">
        <h3>SARA: Section 151(d)(1) &mdash; Exemption Amount (DeepSeek 7B)</h3>
        <div class="example-meta">ID: s151_d_1_neg &middot; Gold label: Contradiction &middot; Section: 151(d)(1)</div>
        <div class="example-prompt">
            <strong>Facts:</strong>
            Alice is entitled to an exemption under section 151(b) for the year 2015. No other taxpayer is entitled to a deduction for Alice in 2015.
            <br><br>
            <strong>Conclusion to evaluate:</strong>
            Alice's exemption amount under section 151(d)(1) is equal to $0.
            <br><br>
            <em style="color:#888; font-size:0.8rem;">Prompt: &ldquo;Does the following conclusion follow from the facts? Answer with: Entailment or Contradiction.&rdquo;</em>
        </div>
        <div class="response-grid">
            <div class="response-box response-wrong">
                <div class="box-header">
                    Base DeepSeek 7B
                    <span class="verdict verdict-wrong">Predicted: unknown</span>
                </div>
Okay, so I need to figure out whether the conclusion about Alice's exemption amount under section 151(d)(1) being $0 follows from the given facts. Let me start by understanding the problem.

First, the facts provided are:
1. Alice is entitled to an exemption under section 151(b) for the year 2015.
2. No other taxpayer is entitled to a deduction for Alice in 2015.

The conclusion is that Alice's exemption amount under section 151(d)(1) is $0.

Hmm, I'm a bit confused about how these sections relate. I know that in the tax code, different sections can have different rules for deductions and exemptions. Section 151(b) might be related to personal exemptions, while 151(d)(1) could be about other types of exemptions, maybe like family exemptions or something else.

Let me break it down. The first fact says Alice is entitled to an exemption under section 151(b). I'm not sure what that exactly means, but maybe it's a personal exemption. The second fact says no other taxpayer is entitled to a<span class="truncated">[...continues]</span></div>
            <div class="response-box response-wrong">
                <div class="box-header">
                    SFT DeepSeek 7B
                    <span class="verdict verdict-wrong">Predicted: unknown</span>
                </div>
Alright, let's try to figure out if the conclusion follows from the given facts. The facts are: "Alice is entitled to an exemption under section 151(b) for the year 2015. No other taxpayer is entitled to a deduction for Alice in 2015." The conclusion is: "Alice's exemption amount under section 151(d)(1) is equal to $0."

First, I need to understand what these statements mean. Section 151(b) likely refers to a dependency exemption, and section 151(d)(1) might be a different type of exemption, perhaps a personal exemption. The fact says Alice is entitled to an exemption under section 151(b) for 2015. That means she gets some amount under that section. Then it says no other taxpayer is entitled to a deduction for Alice in 2015. That might mean that only Alice is entitled to deductions under some section, but it doesn't directly say anything about her exemption amount under section 151(d)(1).

The conclusion claims her exemption under 151(d)(1) is $0. That seems like a specific amount. To <span class="truncated">[...continues]</span></div>
            <div class="response-box response-correct">
                <div class="box-header">
                    GRPO DeepSeek 7B
                    <span class="verdict verdict-correct">Predicted: contradiction</span>
                </div>
Okay, so I need to figure out whether the conclusion that Alice's exemption amount under section 151(d)(1) is equal to $0 follows from the given statutory facts. Let me start by understanding the facts provided.

First, the facts say: "Alice is entitled to an exemption under section 151(b) for the year 2015. No other taxpayer is entitled to a deduction for Alice in 2015." So, this means that Alice is eligible for a deduction under section 151(b), and no one else is.

Now, the conclusion is that her exemption amount under section 151(d)(1) is $0. I need to see if this conclusion logically follows from the facts.

Let me break it down. Section 151(b) and 151(d) are different sections in the tax code. Section 151(b) likely refers to a different type of exemption, perhaps for certain types of income or situations, while 151(d) might be about a different exemption, maybe for other purposes.

The fact says Alice is entitled to an exemption under section 151(b). That doesn't necessarily mea<span class="truncated">[...continues &rarr; concludes: Contradiction]</span></div>
        </div>
    </div>

    <!-- LSAT Example 1: Qwen 8B -->
    <div class="example-card">
        <h3>LSAT: Seminar Schedule &mdash; Constraint Satisfaction (Qwen 8B)</h3>
        <div class="example-meta">Gold label: A &middot; 5-way multiple choice (A&ndash;E)</div>
        <div class="example-prompt">
            <strong>Setup:</strong>
            Of the eight students&mdash;George, Helen, Irving, Kyle, Lenore, Nina, Olivia, and Robert&mdash;in a seminar, exactly six will give individual oral reports during three consecutive days. Each day exactly two reports are given, one in the morning and one in the afternoon.
            Rules: (1) Tuesday is the only day on which George can give a report. (2) Neither Olivia nor Robert can give an afternoon report. (3) If Nina gives a report, then on the next day Helen and Irving must both give reports, unless Nina's report is given on Wednesday.
            <br><br>
            <strong>Question:</strong>
            If George, Nina, and Robert give reports and they do so on different days from one another, which one of the following could be true?
            (A) Helen gives a report on Wednesday. (B) Nina gives a report on Monday. (C) Nina gives a report on Tuesday. (D) Olivia gives a report on Monday. (E) Robert gives a report on Wednesday.
        </div>
        <div class="response-grid">
            <div class="response-box response-wrong">
                <div class="box-header">
                    Base Qwen 8B
                    <span class="verdict verdict-wrong">Predicted: unknown</span>
                </div>
&lt;think&gt;
Okay, let's try to work through this problem step by step. So, we have eight students: George, Helen, Irving, Kyle, Lenore, Nina, Olivia, and Robert. Exactly six of them will give reports over three days&mdash;Monday, Tuesday, Wednesday. Each day has two reports: morning and afternoon. The conditions are:

1. Tuesday is the only day George can give a report.
2. Neither Olivia nor Robert can give an afternoon report.
3. If Nina gives a report, then on the next day Helen and Irving must both give reports, unless Nina's report is on Wednesday.

Additionally, we know that George, Nina, and Robert give reports, and they are on different days. The question is which of the options could be true.

First, let's note the constraints. Let me break them down.

Starting with the first condition: George can only report on Tuesday. So George's report is on Tuesday, either morning or afternoon. But since each day has two reports, but George is one of them. So George is on Tuesday.

Second, Olivia an<span class="truncated">[...continues]</span></div>
            <div class="response-box response-wrong">
                <div class="box-header">
                    SFT Qwen 8B
                    <span class="verdict verdict-wrong">Predicted: unknown</span>
                </div>
&lt;think&gt;
First, I need to parse the problem and formalize the constraints.

We have eight students: George, Helen, Irving, Kyle, Lenore, Nina, Olivia, Robert.
Exactly six will give reports on three consecutive days: Monday, Tuesday, Wednesday.
Each day has two reports: morning and afternoon.
Constraints:
1. Tuesday is the only day on which George can give a report.
2. Neither Olivia nor Robert can give an afternoon report.
3. If Nina gives a report, then on the next day Helen and Irving must both give reports, unless Nina's report is given on Wednesday.

Additional condition: George, Nina, and Robert give reports and they do so on different days from one another.

We need to determine which of the options could be true.

Let's define predicates:
- report(X, D) means student X gives a report on day D.
- morning(D) means the morning session on day D.
- afternoon(D) means the afternoon session on day D.
- But since each day has exactly two reports (morning and afternoon), we can just say r<span class="truncated">[...continues]</span></div>
            <div class="response-box response-correct">
                <div class="box-header">
                    GRPO Qwen 8B
                    <span class="verdict verdict-correct">Predicted: A</span>
                </div>
&lt;think&gt;
Let's break down the problem and apply logical reasoning step by step.

First, identify the constraints:

1. Exactly six students give reports: George, Nina, Robert, and three others (from Helen, Irving, Olivia, Kyle, Lenore, but not all of them).
2. Reports are given on three consecutive days: Monday, Tuesday, Wednesday.
3. Exactly two reports each day: one morning, one afternoon.
4. Tuesday is the only day on which George can give a report.
5. Neither Olivia nor Robert can give an afternoon report.
6. If Nina gives a report, then on the next day Helen and Irving must both give reports, unless Nina's report is given on Wednesday.

Given: George, Nina, and Robert give reports and they do so on different days from one another.

We need to determine which of the options could be true.

Let's formalize the constraints.

Step 1:
(Text) George can only give a report on Tuesday.
(Logic) report(george, X) :- day(X) = tuesday.

Step 2:
(Text) Neither Olivia nor Robert can give an after<span class="truncated">[...continues &rarr; concludes: A]</span></div>
        </div>
    </div>

    <!-- LSAT Example 2: DeepSeek 7B -->
    <div class="example-card">
        <h3>LSAT: Scientist Panel &mdash; Selection Constraints (DeepSeek 7B)</h3>
        <div class="example-meta">Gold label: E &middot; 5-way multiple choice (A&ndash;E)</div>
        <div class="example-prompt">
            <strong>Setup:</strong>
            A panel of five scientists will be formed from three botanists (F, G, H), three chemists (K, L, M), and three zoologists (P, Q, R).
            Rules: (1) The panel must include at least one from each group. (2) If more than one botanist, then at most one zoologist. (3) F and K cannot both be selected. (4) K and M cannot both be selected. (5) If M is selected, both P and R must be selected.
            <br><br>
            <strong>Question:</strong>
            If four of the scientists selected are F, L, Q, and R, which one of the following must be the fifth scientist selected?
            (A) G (B) H (C) K (D) M (E) P
        </div>
        <div class="response-grid">
            <div class="response-box response-wrong">
                <div class="box-header">
                    Base DeepSeek 7B
                    <span class="verdict verdict-wrong">Predicted: unknown</span>
                </div>
Alright, let's tackle this problem step by step. So, we have a panel of five scientists to be formed from three groups: botanists (F, G, H), chemists (K, L, M), and zoologists (P, Q, R). The panel must include at least one from each group. There are several constraints given, and we're told that four of the selected scientists are F, L, Q, and R. We need to figure out which one of the options (G, H, K, M, P) must be the fifth scientist.

First, let's list out the constraints to make sure we don't miss anything:

1. At least one from each group: botanist, chemist, zoologist.
2. If more than one botanist is selected, then at most one zoologist is selected.
3. F and K cannot both be selected.
4. K and M cannot both be selected.
5. If M is selected, both P and R must be selected.

Given that the selected scientists are F, L, Q, R, let's analyze each constraint.

Starting with constraint 1: At least one from each group. We have F, which is a botanist, L, which is a chemist, and Q and R, whi<span class="truncated">[...continues]</span></div>
            <div class="response-box response-wrong">
                <div class="box-header">
                    SFT DeepSeek 7B
                    <span class="verdict verdict-wrong">Predicted: unknown</span>
                </div>
Alright, let's tackle this problem step by step. We need to determine which of the options (G, H, K, M, P) must be the fifth scientist selected given the constraints and the four already selected: F, L, Q, R.

First, let's restate the problem in my own words. We have a panel of five scientists: three botanists (F, G, H), three chemists (K, L, M), and three zoologists (P, Q, R). The panel must include at least one from each type. There are additional constraints:

1. If more than one botanist is selected, then at most one zoologist is selected.
2. F and K cannot both be selected.
3. K and M cannot both be selected.
4. If M is selected, both P and R must be selected.

We are told that four scientists are selected: F, L, Q, R. We need to find the fifth scientist from the options.

Let's list the given four: F (botanist), L (chemist), Q (zoologist), R (zoologist). So far, we have one botanist (F), one chemist (L), and two zoologists (Q, R). We need at least one from each type, so we are mi<span class="truncated">[...continues]</span></div>
            <div class="response-box response-correct">
                <div class="box-header">
                    GRPO DeepSeek 7B
                    <span class="verdict verdict-correct">Predicted: E (P)</span>
                </div>
Okay, so I need to figure out which scientist must be the fifth member of the panel given the constraints. Let's start by listing all the premises.

First, the panel must include at least one botanist, one chemist, and one zoologist. So, we have three categories: botanists (F, G, H), chemists (K, L, M), and zoologists (P, Q, R). So, the panel must have at least one from each.

Next, the selection has some additional constraints:

1. If more than one botanist is selected, then at most one zoologist is selected.
2. F and K cannot both be selected.
3. K and M cannot both be selected.
4. If M is selected, both P and R must be selected.

Now, the four scientists already selected are F, L, Q, and R. So, let's see what we have.

First, F is a botanist, L is a chemist, Q is a zoologist, and R is a zoologist. So, we have one botanist, one chemist, and two zoologists. But the panel must have at least one of each, so that's fine becaus<span class="truncated">[...continues &rarr; concludes: E (P)]</span></div>
        </div>
    </div>
</div>

<!-- Analysis -->
<div class="analysis">
    <h2>Analysis</h2>

    <h3>The SFT trap: format overfitting hurts transfer</h3>
    <p>The most striking finding is that SFT consistently <em>decreases</em> performance compared to the base model on both benchmarks:</p>
    <ul>
        <li>DeepSeek SFT drops from 35% to 5% on SARA (&minus;30pp) and from 15.2% to 9.1% on LSAT (&minus;6.1pp)</li>
        <li>Qwen SFT drops from 16% to 11% on SARA (&minus;5pp) and from 21.7% to 16.1% on LSAT (&minus;5.6pp)</li>
    </ul>
    <p>SFT teaches the model to produce LogicBench-style structured output, but this format training actually <em>interferes</em> with the model's natural reasoning ability on out-of-domain tasks. The model tries to fit legal/constraint reasoning into a format it learned for propositional logic, and fails at both the format and the reasoning.</p>

    <h3>GRPO's consistency reward teaches transferable reasoning</h3>
    <p>GRPO recovers from the SFT performance collapse and surpasses the base model, especially on Qwen:</p>
    <ul>
        <li><strong>Qwen SARA:</strong> 43% GRPO vs 16% Base (+27pp). The largest gain. GRPO Qwen learns to systematically decompose statutory conditions even though it was only trained on propositional/FOL logic.</li>
        <li><strong>Qwen LSAT:</strong> 28.3% GRPO vs 21.7% Base (+6.6pp). Above the 20% random baseline, with consistent improvement.</li>
        <li><strong>DeepSeek SARA:</strong> 40% GRPO vs 35% Base (+5pp). More modest, as DeepSeek-R1-Distill already has strong baseline reasoning.</li>
        <li><strong>DeepSeek LSAT:</strong> 17% GRPO vs 15.2% Base (+1.8pp). Small but consistent.</li>
    </ul>

    <h3>Why is DeepSeek's base model so strong?</h3>
    <p>DeepSeek-R1-Distill-Qwen-7B already has strong reasoning capabilities from distillation. Its base performance (35% SARA, 15.2% LSAT) is competitive with Qwen's GRPO-trained model. This explains the smaller GRPO improvement for DeepSeek: there is less room to improve when the baseline is already strong.</p>

    <h3>Key observations</h3>
    <ul>
        <li><strong>Parse success does not equal accuracy:</strong> Base DeepSeek has 84% parse success on SARA (high) but 35% accuracy. GRPO DeepSeek has only 6% parse success but 40% accuracy. The model can reach correct answers through free-form reasoning without always using XML step tags.</li>
        <li><strong>Basic mode fails uniformly:</strong> All models perform 0&ndash;4% in basic (no-CoT) mode. These tasks genuinely require multi-step reasoning; the model cannot shortcut to the answer.</li>
        <li><strong>Consistency is domain-limited:</strong> SAT consistency rates are near zero because the SAT verifier cannot evaluate numerical computations (tax calculations) or constraint satisfaction logic. This is expected and motivates domain-specific verifiers (Paper 2).</li>
    </ul>

    <h3>Limitations</h3>
    <ul>
        <li>DeepSeek GRPO improvement over base is modest (+5pp SARA, +1.8pp LSAT). The strongest transfer results are with Qwen.</li>
        <li>Absolute LSAT accuracy remains below the 20% random baseline for DeepSeek models. These benchmarks are hard for 7&ndash;8B parameter models.</li>
        <li>No domain-specific few-shot examples were used during evaluation, which may disadvantage all models equally.</li>
        <li>Generated outputs in the JSON are truncated at 1000 characters for storage. Full reasoning chains are longer.</li>
    </ul>
</div>

<div class="footer">
    Updated February 21, 2026 &middot;
    RAILS (Reasoning with Automatically Integrated Logical Supervision) &middot;
    ProofContinuity
</div>

</body>
</html>
